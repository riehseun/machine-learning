{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f92e80d-2de3-4dc2-bafa-4d75ca3c973d",
   "metadata": {},
   "source": [
    "# Search ranking\n",
    "\n",
    "### Scope\n",
    "- A general search enginer like Google.\n",
    "\n",
    "### Scale\n",
    "- How many websites to search from? Billions of documents.\n",
    "- How many requests per second? 10k queries per second.\n",
    "\n",
    "### Personalization\n",
    "- Assume user is logged in and historical search data of user is available.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "### Online metrics\n",
    "- Click through rate\n",
    "    - (number of clicks / number of impressions or views) \n",
    "    - Unsuccessful clicks would also be part of this metric.\n",
    "- Session success rate\n",
    "    - Dwell time: time user spent viewing a page.\n",
    "    - (number of sucessful sessions (dwell time > 10s) / number of total sessions)\n",
    "- Time to success\n",
    "    - Low number of quries means the system was good at guess what user wanted.\n",
    "\n",
    "### Offline metrics\n",
    "- Ground truth: actual outputs desired by the system. In this case, it is the rating provided by humans.\n",
    "- Assume the search engine returns documents $D_{1}, D_{2}, D_{3}, D_{4}$ in the order of relevance.\n",
    "- Assume human rates the documetns on scale of $0$ to $3$ ($3$ is highly relevant, $0$ is merely relevant) such that\n",
    "    - $D_{1} = 3$, $D_{2} = 2$, $D_{3} = 3$, $D_{4} = 0$ \n",
    "- Cumulative gain simply adds.\n",
    "    - $3+2+3+0 = 8$\n",
    "- Discounted cumulative gain (DCG) penalizes if highly relevant document appears lower in the result.\n",
    "    - $\\dfrac{3}{log_{2}(1+1)}+\\dfrac{2}{log_{2}(2+1)}+\\dfrac{3}{log_{2}(3+1)}+\\dfrac{0}{log_{2}(4+1)} = 3+1.262+1.5+0 = 5.762$\n",
    "- Normalized discounted cumulative gain (NDCG) is computed by (DCG / IDCG) where IDCG is DCG of ideal ordering.\n",
    "    - NDCG does not penalize irrelevant search result.\n",
    "    \n",
    "## Architecture\n",
    "\n",
    "<img src=\"img/search_engine1.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "### Layered model approach \n",
    "\n",
    "<img src=\"img/search_engine2.png\" style=\"width:1000px;height:200px;\">\n",
    "\n",
    "### Query rewriting\n",
    "- Queries are often poorly worded.\n",
    "- Increases recall. (return larger set of relevant results)\n",
    "\n",
    "Spell checker\n",
    "- Corrects spelling mistakes.\n",
    "\n",
    "Query expansion\n",
    "- Ex. expand \"restaurant\" to \"food\" or \"recipe\" to look for all candidates.\n",
    "\n",
    "### Query understanding\n",
    "- Intent behind query\n",
    "    - Ex. \"gas station\" has local intent.\n",
    "    - Ex. \"earthquake\" has newsy intent.\n",
    "    \n",
    "### Document selection\n",
    "- Select set of documents that are relevant to query.\n",
    "- Focused on recall. \n",
    "\n",
    "<img src=\"img/search_engine3.png\" style=\"width:400px;height:200px;\">\n",
    "\n",
    "#### Inverted index\n",
    "- Map words to documents.\n",
    "\n",
    "<img src=\"img/search_engine4.png\" style=\"width:600px;height:400px;\">\n",
    "\n",
    "#### Selection criteria\n",
    "- Go to index and retrive all documents based on this criteria.\n",
    "\n",
    "<img src=\"img/search_engine5.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "#### Scoring scheme\n",
    "- Personalization measures searcher's profile such as age, gender, interest, location.\n",
    "\n",
    "<img src=\"img/search_engine6.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "### Ranker\n",
    "- Find best order of documents.\n",
    "- Stage 1 \n",
    "    - Find subset of document that should be passed to stage 2.\n",
    "    - Use simpler algorithm like logistic regression to do binary classification.\n",
    "    - Objective function takes pointwise approach.\n",
    "- Stage 2\n",
    "    - Perform complex algorithm like LambdaMART (If using offline NDCG, which is based on human-rated data) or LambdaRank (If using online training data) to do document ordering. \n",
    "    - Objective function takes pairwise approach.\n",
    "        - Get as many pairs of document in the right order as possible.\n",
    "    \n",
    "### Blender\n",
    "- Provides various results like posts, images, news, videos.\n",
    "- Avoid displaying results from a single or few sources.\n",
    "- Outputs final result page to users.\n",
    "\n",
    "### Filter \n",
    "- Filter inappropriate result despite good user engagement.\n",
    "- Training data can come from human raters and/or online feedback.\n",
    "- Extra features could be considered such as\n",
    "    - Website historical report rate\n",
    "    - Sexually explicit terms used\n",
    "    - Domain name\n",
    "    - Website description\n",
    "    - Images used on the website\n",
    "- Use classification to determine if result inappropriate or not.\n",
    "\n",
    "## Training data generation\n",
    "- Takes online user data and generates positive and negative examples.\n",
    "\n",
    "### Binary classification (pointwise approach)\n",
    "- Document is either relevant or irrevant.\n",
    "    - If user spent some time in the document, mark it relevant.\n",
    "    - If user immediate backed after clicking the document, mark it irrelevant.\n",
    "- We may never get enough negative examples.\n",
    "    - Maybe treat all document displayed in 50th page in Google as negative.\n",
    "\n",
    "### Train / test split\n",
    "\n",
    "<img src=\"img/search_engine8.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "### Document ordering (pairwise approach)\n",
    "- The goal is to minimize inversion. (number of wrong orders compared to ground truth) \n",
    "- Rank the document based on user activity on each document and use that as training data.\n",
    "\n",
    "## Feature engineering\n",
    "\n",
    "<img src=\"img/search_engine7.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "### Searcher (Assume the user is logged in)\n",
    "- Age\n",
    "- Gender\n",
    "- Interest\n",
    "\n",
    "### Query\n",
    "- History\n",
    "    - For example, query \"earthquake\" historically was related to recent news.\n",
    "- Intent\n",
    "    - For example, query \"Pizza places\" has \"local\" intent, thus should give higher rank to pizza places located nearby the searcher.\n",
    "    \n",
    "### Document\n",
    "- Page rank\n",
    "    - For example, the number of quality documents that link to it.\n",
    "- Radius\n",
    "    - For example, coffee shop in Toronto is relevant to people in 10km radicus but Eiffel tower has global scope.\n",
    "    \n",
    "### Context\n",
    "- Time of day\n",
    "    - For example, query \"restaurant\" should consider restaurant open at the time of query.\n",
    "- Recent query\n",
    "    - Take a look at previous quries. For example, \"python\" -> \"python list\"  \n",
    "    \n",
    "### Searcher-document\n",
    "- Distance\n",
    "    - For queries regarding locations, consider distance between searcher and matching location.\n",
    "- History\n",
    "    - For example, if searcher looked for video document in the past, then vidoe document would be more relevant to the searcher.\n",
    "    \n",
    "### Query-document\n",
    "- Text match\n",
    "    - Matches in the title, metadata, content of document\n",
    "- N-gram match\n",
    "    - For example, \"Seattle tourism guide\". Find text match for the combinations of three words.\n",
    "    - TF-IDF\n",
    "        - TF: (Term Frequency) importance of each term in the document.\n",
    "        - IDF: (Inverse Document Frequency) how much information a particular term provides.\n",
    "- Click rate\n",
    "    - User's historical engagement with document.\n",
    "- Embeddings\n",
    "    - Find relationship between query and document.\n",
    "    - Similarity score is computed between query vector and each document vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9296e87-472d-48dc-bbe4-7d7b5648be3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
