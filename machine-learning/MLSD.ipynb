{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2885da0-d0e0-4966-8f80-88c881accbdb",
   "metadata": {},
   "source": [
    "# Overview (Example: Google Search Engine)\n",
    "\n",
    "Latency and scale\n",
    "- Return results in 100 miliseconds or 500 miliseconds?\n",
    "- How many requests to handle per second?\n",
    "\n",
    "Define metrics\n",
    "- Offline metrics \n",
    "    - Binary classification: AUC, log loss, precision, recall, F1\n",
    "    - search engine ranking: NDCG\n",
    "- Online mertics\n",
    "    - component-wise: NDCG\n",
    "    - end-to-end: user engagement and retention rate\n",
    "    \n",
    "Architecture for scale\n",
    "- Funnel approach where each stage has fewer data to process.\n",
    "\n",
    "Training data\n",
    "- If users click on search enginer result, count it as positive.\n",
    "\n",
    "Feature engineering\n",
    "- Investigate the problem.\n",
    "\n",
    "Model training\n",
    "- In funnel approach, simpler models at the top and complex models at the bottom.\n",
    "\n",
    "Offline evaluation\n",
    "- Evaludate models on validation set.\n",
    "\n",
    "Online evaluation\n",
    "- Test result will determine whether to deploy the model or not.\n",
    "\n",
    "Iterations\n",
    "- If model performs well offline, but not online. Need to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99e543-5732-4d06-ae2b-676177b89b61",
   "metadata": {},
   "source": [
    "# Performance and capacity\n",
    "\n",
    "Performance\n",
    "- Ensure we return results back within given time.\n",
    "\n",
    "Capacity\n",
    "- Load that the system can handled (Ex. number of queries per second)\n",
    "\n",
    "Training time:\n",
    "- How much data and capacity do we need?\n",
    "  \n",
    "Evaludation time:\n",
    "- What is SLA to meet while serving the model?\n",
    "    \n",
    "Paramaters\n",
    "- $n$: number of training examples.\n",
    "- $f$: number of features.\n",
    "- $n_{l_{i}}$: number of neurons in $i$th layer\n",
    "- $e$: number of epochs.    \n",
    "- $n_{trees}$: number of trees.\n",
    "- $d$: max depth of tree.\n",
    "    \n",
    "Complexities    \n",
    "- Linear and logistic regression (batch)\n",
    "    - Train: $O(nfe)$\n",
    "    - Evaluation: $O(f)$\n",
    "- Neural network\n",
    "    - Train: exponential (varies between models)\n",
    "    - Evaluation: $O(fn_{l_{i}} + n_{l_{i}}n_{l_{i}} + \\dots)$\n",
    "- Multiple additive regression trees (MART)\n",
    "    - Train: $O(ndfn_{trees})$\n",
    "    - Evaluation: $O(dfn_{trees})$\n",
    "    \n",
    "Where\n",
    "- Training complexity:\n",
    "    - Time taken to train.\n",
    "- Evaluation complexity:\n",
    "    - Time taken to evaluate inputs at testing time.\n",
    "- Sample complexity: \n",
    "    - Total number of samples to learn target function.\n",
    "    \n",
    "Funnel approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c129aed-34a0-4c5b-820c-130010703827",
   "metadata": {},
   "source": [
    "# Training data \n",
    "\n",
    "Make sure to capture all kinds of patterns in each split.\n",
    "- Training data: fit model parameters.\n",
    "- Validation data: hyper parameter tuning.\n",
    "- Test data: predict on data the model has not seen before.\n",
    "\n",
    "Data filtering\n",
    "- Cleaning up data\n",
    "    - Handle missing data, outliers, duplicates.\n",
    "    - Drop out irrelevant features.\n",
    "- Removing bias\n",
    "- Boostraping new items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af74dff-3e79-4a33-a024-995a0b2d44d9",
   "metadata": {},
   "source": [
    "# Online experimentation\n",
    "\n",
    "A/B testing\n",
    "- Original version is control and new version is variation.\n",
    "- Determine if variation is significantly better than control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d995af7-3cdf-4ca6-9d2f-c9014107ce7e",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "- Encode entities (words, images, etc) into vector space.\n",
    "\n",
    "Text embeddings\n",
    "- Word2vec\n",
    "    - Uses shallow NN (a single hidden layer) from a large corpus of text data.\n",
    "    - Uses neighboring words to predict the current words, and generates embeddings during this process.\n",
    "        - Ex. Continuous bag of words (CBOW)\n",
    "    - Uses current word to predict surrounding words.\n",
    "        - Ex. Skipgram\n",
    "    - Has a fixed vector for every term. (does not consider the context)\n",
    "- Embedding from Language Models (ELMo)\n",
    "    - Uses bi-directional LSTM to capture words before and after current word.\n",
    "- Bidirectional Encoder Representations from Transformers (BERT)\n",
    "    - Uses attention to see all words in the context, and utilizes only the ones that help the prediction.\n",
    "    \n",
    "Image embeddings\n",
    "- Auto-encoders\n",
    "    - Consists of encoder and decoder.\n",
    "    - Compress raw image pixel data into small dimension, then decompress re-generate the same input image. Last layer of encoder determines the dimension of the embedding.\n",
    "    - Tries to minimize the difference between original and generated pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c0c89-6799-484e-8319-3b740271d5e4",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "Fine tuning\n",
    "- Change/tune the existing parameters in a pre-trained network. \n",
    "- How many layers can we freeze (the weights) and how many layers we want to fune tune?\n",
    "- Eg. for image classification, once we understand convolution, pooling, full connected layers, we can decide how many final layers we want to fine tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95261927-2f53-4630-9104-9d79e9332ec3",
   "metadata": {},
   "source": [
    "# Model debugging and testing\n",
    "\n",
    "- Launch the first version quickly and interate to improve it using real traffic.\n",
    "\n",
    "Debugging\n",
    "- Feature distribution change\n",
    "    - Real traffic data can change due to seasonality.\n",
    "- Feature logging issue\n",
    "    - Feature was computed differently during training and evaluation time.\n",
    "- Overfitting or underfitting\n",
    "- Missing important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296b590-9da8-448f-9000-5c48a0c7d91b",
   "metadata": {},
   "source": [
    "# Search ranking\n",
    "\n",
    "- Assume\n",
    "    - Billions of documents to search from.\n",
    "    - 10K quries per second.\n",
    "    \n",
    "## Metrics\n",
    "\n",
    "- Online metrics\n",
    "    - Click-through rate = # of clicks / # of impressions or views\n",
    "    - Sucessful session rate = # of successful sessions / # of total sessions\n",
    "        - Sucessful session is when users spend 10 seconds or longer viewing the page.\n",
    "    - Time to success (low number of queries per session)\n",
    "- Offline metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c09a8-a37f-4e4f-9174-dbf3f7751ce3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Search ranking\n",
    "\n",
    "## Scope\n",
    "- A general search enginer like Google.\n",
    "\n",
    "## Scale\n",
    "- How many websites to search from? Billions of documents.\n",
    "- How many requests per second? 10k queries per second.\n",
    "\n",
    "## Personalization\n",
    "- Assume user is logged in and historical search data of user is available.\n",
    "\n",
    "## Online metrics\n",
    "- Click through rate: number of clicks / number of impressions (or views) \n",
    "    - Unsuccessful clicks would also me part of this metric.\n",
    "- Dwell time: time user spent viewing a page.\n",
    "- Session success rate: number of sucessful sessions (dwell time > 10s) / number of total sessions\n",
    "\n",
    "## Offline metrics\n",
    "- Ground truth: actual outputs desired by the system. In this case, it is the rating provided by humans.\n",
    "- Assume the search engine returns documents $D_{1}, D_{2}, D_{3}, D_{4}$ in the order of relevance.\n",
    "- Assume human rates the documetns on scale of 0-3 (3 is highly relevant, 0 is merely relevant) such that\n",
    "    - $D_{1} = 3$, $D_{2} = 2$, $D_{3} = 3$, $D_{4} = 0$ \n",
    "- Cumulative gain simply adds\n",
    "    - $3+2+3+0 = 8$\n",
    "- Discounted cumulative gain penalizes if highly relevant document appears lower in the result.\n",
    "    - $\\dfrac{3}{log_{2}(1+1)}+\\dfrac{2}{log_{2}(2+1)}+\\dfrac{3}{log_{2}(3+1)}+\\dfrac{0}{log_{2}(4+1)} = 3+1.262+1.5+0 = 5.762$\n",
    "- NDCG is computed by (DCG / IDCG) where IDCG is DCG of ideal ordering.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "<img src=\"img/search_engine1.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "## Query rewriting\n",
    "- Queries are often poorly worded.\n",
    "- Increases recall. (return larger set of relevant results)\n",
    "\n",
    "Spell checker\n",
    "- Corrects spelling mistakes.\n",
    "\n",
    "Query expansion\n",
    "- Ex. expand \"restaurant\" to \"food\" or \"recipe\" to look for all candidates.\n",
    "\n",
    "## Query understanding\n",
    "- Intent behind query:\n",
    "    - Ex. \"gas station\" has local intent.\n",
    "    - Ex. \"earthquake\" has newsy intent.\n",
    "    \n",
    "## Document selection\n",
    "- Select set of documents relevant to query.\n",
    "\n",
    "<img src=\"img/search_engine3.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Inverted index\n",
    "\n",
    "<img src=\"img/search_engine4.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Selection criteria\n",
    "\n",
    "<img src=\"img/search_engine5.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Scoring scheme\n",
    "\n",
    "<img src=\"img/search_engine6.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Personalization measures searcher's profile such as age, gender, interest, location.\n",
    "\n",
    "## Ranker\n",
    "- Find best order of documents.\n",
    "- Stage 1 \n",
    "    - Find subset of document that should be passed to stage 2.\n",
    "    - Use simpler algorithm like linear regression to do binary classification.\n",
    "- Stage 2\n",
    "    - Perform complex algorithm like LambdaMART or LambdaRank to do document ordering.\n",
    "\n",
    "## Blender\n",
    "- Provides various results like posts, images, news, videos.\n",
    "\n",
    "## Training data generation\n",
    "- Takes online user data and generates positive and negative examples.\n",
    "\n",
    "Binary classification\n",
    "- Document is either relevant or irrevant.\n",
    "    - If user spent some time in the document, mark it relevant.\n",
    "    - If user immediate backed after clicking the document, mark it irrelevant.\n",
    "    \n",
    "<img src=\"img/search_engine8.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Document ordering\n",
    "- The goal is to minimize inversion. (number of wrong orders compared to ground truth) \n",
    "- Rank the document based on user activity on each document and use that as training data.\n",
    "\n",
    "## Layered model approach \n",
    "\n",
    "<img src=\"img/search_engine2.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "## Feature engineering\n",
    "\n",
    "<img src=\"img/search_engine7.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "Searcher (Assume the user is logged in)\n",
    "- Age\n",
    "- Gender\n",
    "- Interest\n",
    "\n",
    "Query\n",
    "- History\n",
    "    - For example, query \"earthquake\" historically was related to recent news.\n",
    "- Intent\n",
    "    - For example, query \"Pizza places\" has \"local\" intent, thus should give higher rank to pizza places located nearby the searcher.\n",
    "    \n",
    "Document\n",
    "- Page rank\n",
    "    - For example, the number of quality documents that link to it.\n",
    "- Radius\n",
    "    - For example, coffee shop in Toronto is relevant to people in 10km radicus but Eiffel tower has global scope.\n",
    "    \n",
    "Context\n",
    "- Time of day\n",
    "    - For example, query \"restaurant\" should consider restaurant open at the time of query.\n",
    "- Recent query\n",
    "    - Take a look at previous quries. For example, \"python\" -> \"python list\"  \n",
    "    \n",
    "Searcher-document\n",
    "- Distance\n",
    "    - For queries regarding locations, consider distance between searcher and matching location.\n",
    "- History\n",
    "    - For example, if searcher looked for video document in the past, then vidoe document would be more relevant to the searcher.\n",
    "    \n",
    "Query-document\n",
    "- Text match\n",
    "    - Matches in the title, metadata, content of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ffad5-b44d-4100-b5ae-9b42a312fcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
