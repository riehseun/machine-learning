{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2885da0-d0e0-4966-8f80-88c881accbdb",
   "metadata": {},
   "source": [
    "# Overview (Example: Google Search Engine)\n",
    "\n",
    "Latency and scale\n",
    "- Return results in 100 miliseconds or 500 miliseconds?\n",
    "- How many requests to handle per second?\n",
    "\n",
    "Define metrics\n",
    "- Offline metrics \n",
    "    - Binary classification: AUC, log loss, precision, recall, F1\n",
    "    - search engine ranking: NDCG\n",
    "- Online mertics\n",
    "    - component-wise: NDCG\n",
    "    - end-to-end: user engagement and retention rate\n",
    "    \n",
    "Architecture for scale\n",
    "- Funnel approach where each stage has fewer data to process.\n",
    "\n",
    "Training data\n",
    "- If users click on search enginer result, count it as positive.\n",
    "\n",
    "Feature engineering\n",
    "- Investigate the problem.\n",
    "\n",
    "Model training\n",
    "- In funnel approach, simpler models at the top and complex models at the bottom.\n",
    "\n",
    "Offline evaluation\n",
    "- Evaludate models on validation set.\n",
    "\n",
    "Online evaluation\n",
    "- Test result will determine whether to deploy the model or not.\n",
    "\n",
    "Iterations\n",
    "- If model performs well offline, but not online. Need to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99e543-5732-4d06-ae2b-676177b89b61",
   "metadata": {},
   "source": [
    "# Performance and capacity\n",
    "\n",
    "Performance\n",
    "- Ensure we return results back within given time.\n",
    "\n",
    "Capacity\n",
    "- Load that the system can handled (Ex. number of queries per second)\n",
    "\n",
    "Training time:\n",
    "- How much data and capacity do we need?\n",
    "  \n",
    "Evaludation time:\n",
    "- What is SLA to meet while serving the model?\n",
    "    \n",
    "Paramaters\n",
    "- $n$: number of training examples.\n",
    "- $f$: number of features.\n",
    "- $n_{l_{i}}$: number of neurons in $i$th layer\n",
    "- $e$: number of epochs.    \n",
    "- $n_{trees}$: number of trees.\n",
    "- $d$: max depth of tree.\n",
    "    \n",
    "Complexities    \n",
    "- Linear and logistic regression (batch)\n",
    "    - Train: $O(nfe)$\n",
    "    - Evaluation: $O(f)$\n",
    "- Neural network\n",
    "    - Train: exponential (varies between models)\n",
    "    - Evaluation: $O(fn_{l_{i}} + n_{l_{i}}n_{l_{i}} + \\dots)$\n",
    "- Multiple additive regression trees (MART)\n",
    "    - Train: $O(ndfn_{trees})$\n",
    "    - Evaluation: $O(dfn_{trees})$\n",
    "    \n",
    "Where\n",
    "- Training complexity:\n",
    "    - Time taken to train.\n",
    "- Evaluation complexity:\n",
    "    - Time taken to evaluate inputs at testing time.\n",
    "- Sample complexity: \n",
    "    - Total number of samples to learn target function.\n",
    "    \n",
    "Funnel approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c129aed-34a0-4c5b-820c-130010703827",
   "metadata": {},
   "source": [
    "# Training data \n",
    "\n",
    "Make sure to capture all kinds of patterns in each split.\n",
    "- Training data: fit model parameters.\n",
    "- Validation data: hyper parameter tuning.\n",
    "- Test data: predict on data the model has not seen before.\n",
    "\n",
    "Data filtering\n",
    "- Cleaning up data\n",
    "    - Handle missing data, outliers, duplicates.\n",
    "    - Drop out irrelevant features.\n",
    "- Removing bias\n",
    "- Boostraping new items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af74dff-3e79-4a33-a024-995a0b2d44d9",
   "metadata": {},
   "source": [
    "# Online experimentation\n",
    "\n",
    "A/B testing\n",
    "- Original version is control and new version is variation.\n",
    "- Determine if variation is significantly better than control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d995af7-3cdf-4ca6-9d2f-c9014107ce7e",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "- Encode entities (words, images, etc) into vector space.\n",
    "\n",
    "Text embeddings\n",
    "- Word2vec\n",
    "    - Uses shallow NN (a single hidden layer) from a large corpus of text data.\n",
    "    - Uses neighboring words to predict the current words, and generates embeddings during this process.\n",
    "        - Ex. Continuous bag of words (CBOW)\n",
    "    - Uses current word to predict surrounding words.\n",
    "        - Ex. Skipgram\n",
    "    - Has a fixed vector for every term. (does not consider the context)\n",
    "- Embedding from Language Models (ELMo)\n",
    "    - Uses bi-directional LSTM to capture words before and after current word.\n",
    "- Bidirectional Encoder Representations from Transformers (BERT)\n",
    "    - Uses attention to see all words in the context, and utilizes only the ones that help the prediction.\n",
    "    \n",
    "Image embeddings\n",
    "- Auto-encoders\n",
    "    - Consists of encoder and decoder.\n",
    "    - Compress raw image pixel data into small dimension, then decompress re-generate the same input image. Last layer of encoder determines the dimension of the embedding.\n",
    "    - Tries to minimize the difference between original and generated pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c0c89-6799-484e-8319-3b740271d5e4",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "Fine tuning\n",
    "- Change/tune the existing parameters in a pre-trained network. \n",
    "- How many layers can we freeze (the weights) and how many layers we want to fune tune?\n",
    "- Eg. for image classification, once we understand convolution, pooling, full connected layers, we can decide how many final layers we want to fine tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95261927-2f53-4630-9104-9d79e9332ec3",
   "metadata": {},
   "source": [
    "# Model debugging and testing\n",
    "\n",
    "- Launch the first version quickly and interate to improve it using real traffic.\n",
    "\n",
    "Debugging\n",
    "- Feature distribution change\n",
    "    - Real traffic data can change due to seasonality.\n",
    "- Feature logging issue\n",
    "    - Feature was computed differently during training and evaluation time.\n",
    "- Overfitting or underfitting\n",
    "- Missing important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296b590-9da8-448f-9000-5c48a0c7d91b",
   "metadata": {},
   "source": [
    "# Search ranking\n",
    "\n",
    "- Assume\n",
    "    - Billions of documents to search from.\n",
    "    - 10K quries per second.\n",
    "    \n",
    "## Metrics\n",
    "\n",
    "- Online metrics\n",
    "    - Click-through rate = # of clicks / # of impressions or views\n",
    "    - Sucessful session rate = # of successful sessions / # of total sessions\n",
    "        - Sucessful session is when users spend 10 seconds or longer viewing the page.\n",
    "    - Time to success (low number of queries per session)\n",
    "- Offline metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c09a8-a37f-4e4f-9174-dbf3f7751ce3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Search ranking\n",
    "\n",
    "## Scope\n",
    "- A general search enginer like Google.\n",
    "\n",
    "## Scale\n",
    "- How many websites to search from? Billions of documents.\n",
    "- How many requests per second? 10k queries per second.\n",
    "\n",
    "## Personalization\n",
    "- Assume user is logged in and historical search data of user is available.\n",
    "\n",
    "## Online metrics\n",
    "- Click through rate: number of clicks / number of impressions (or views) \n",
    "    - Unsuccessful clicks would also me part of this metric.\n",
    "- Dwell time: time user spent viewing a page.\n",
    "- Session success rate: number of sucessful sessions (dwell time > 10s) / number of total sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ffad5-b44d-4100-b5ae-9b42a312fcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
