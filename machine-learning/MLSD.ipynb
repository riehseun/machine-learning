{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2885da0-d0e0-4966-8f80-88c881accbdb",
   "metadata": {},
   "source": [
    "# Overview (Example: Google Search Engine)\n",
    "\n",
    "Latency and scale\n",
    "- Return results in 100 miliseconds or 500 miliseconds?\n",
    "- How many requests to handle per second?\n",
    "\n",
    "Define metrics\n",
    "- Offline metrics \n",
    "    - Binary classification: AUC, log loss, precision, recall, F1\n",
    "    - search engine ranking: NDCG\n",
    "- Online mertics\n",
    "    - component-wise: NDCG\n",
    "    - end-to-end: user engagement and retention rate\n",
    "    \n",
    "Architecture for scale\n",
    "- Funnel approach where each stage has fewer data to process.\n",
    "\n",
    "Training data\n",
    "- If users click on search enginer result, count it as positive.\n",
    "\n",
    "Feature engineering\n",
    "- Investigate the problem.\n",
    "\n",
    "Model training\n",
    "- In funnel approach, simpler models at the top and complex models at the bottom.\n",
    "\n",
    "Offline evaluation\n",
    "- Evaludate models on validation set.\n",
    "\n",
    "Online evaluation\n",
    "- Test result will determine whether to deploy the model or not.\n",
    "\n",
    "Iterations\n",
    "- If model performs well offline, but not online. Need to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99e543-5732-4d06-ae2b-676177b89b61",
   "metadata": {},
   "source": [
    "# Performance and capacity\n",
    "\n",
    "Performance\n",
    "- Ensure we return results back within given time.\n",
    "\n",
    "Capacity\n",
    "- Load that the system can handled (Ex. number of queries per second)\n",
    "\n",
    "Training time:\n",
    "- How much data and capacity do we need?\n",
    "  \n",
    "Evaludation time:\n",
    "- What is SLA to meet while serving the model?\n",
    "    \n",
    "Paramaters\n",
    "- $n$: number of training examples.\n",
    "- $f$: number of features.\n",
    "- $n_{l_{i}}$: number of neurons in $i$th layer\n",
    "- $e$: number of epochs.    \n",
    "- $n_{trees}$: number of trees.\n",
    "- $d$: max depth of tree.\n",
    "    \n",
    "Complexities    \n",
    "- Linear and logistic regression (batch)\n",
    "    - Train: $O(nfe)$\n",
    "    - Evaluation: $O(f)$\n",
    "- Neural network\n",
    "    - Train: exponential (varies between models)\n",
    "    - Evaluation: $O(fn_{l_{i}} + n_{l_{i}}n_{l_{i}} + \\dots)$\n",
    "- Multiple additive regression trees (MART)\n",
    "    - Train: $O(ndfn_{trees})$\n",
    "    - Evaluation: $O(dfn_{trees})$\n",
    "    \n",
    "Where\n",
    "- Training complexity:\n",
    "    - Time taken to train.\n",
    "- Evaluation complexity:\n",
    "    - Time taken to evaluate inputs at testing time.\n",
    "- Sample complexity: \n",
    "    - Total number of samples to learn target function.\n",
    "    \n",
    "Funnel approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c129aed-34a0-4c5b-820c-130010703827",
   "metadata": {},
   "source": [
    "# Training data \n",
    "\n",
    "Make sure to capture all kinds of patterns in each split.\n",
    "- Training data: fit model parameters.\n",
    "- Validation data: hyper parameter tuning.\n",
    "- Test data: predict on data the model has not seen before.\n",
    "\n",
    "Data filtering\n",
    "- Cleaning up data\n",
    "    - Handle missing data, outliers, duplicates.\n",
    "    - Drop out irrelevant features.\n",
    "- Removing bias\n",
    "- Boostraping new items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af74dff-3e79-4a33-a024-995a0b2d44d9",
   "metadata": {},
   "source": [
    "# Online experimentation\n",
    "\n",
    "A/B testing\n",
    "- Original version is control and new version is variation.\n",
    "- Determine if variation is significantly better than control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d995af7-3cdf-4ca6-9d2f-c9014107ce7e",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "- Encode entities (words, images, etc) into vector space.\n",
    "\n",
    "Text embeddings\n",
    "- Word2vec\n",
    "    - Uses shallow NN (a single hidden layer) from a large corpus of text data.\n",
    "    - Uses neighboring words to predict the current words, and generates embeddings during this process.\n",
    "        - Ex. Continuous bag of words (CBOW)\n",
    "    - Uses current word to predict surrounding words.\n",
    "        - Ex. Skipgram\n",
    "    - Has a fixed vector for every term. (does not consider the context)\n",
    "- Embedding from Language Models (ELMo)\n",
    "    - Uses bi-directional LSTM to capture words before and after current word.\n",
    "- Bidirectional Encoder Representations from Transformers (BERT)\n",
    "    - Uses attention to see all words in the context, and utilizes only the ones that help the prediction.\n",
    "    \n",
    "Image embeddings\n",
    "- Auto-encoders\n",
    "    - Consists of encoder and decoder.\n",
    "    - Compress raw image pixel data into small dimension, then decompress re-generate the same input image. Last layer of encoder determines the dimension of the embedding.\n",
    "    - Tries to minimize the difference between original and generated pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c0c89-6799-484e-8319-3b740271d5e4",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "Fine tuning\n",
    "- Change/tune the existing parameters in a pre-trained network. \n",
    "- How many layers can we freeze (the weights) and how many layers we want to fune tune?\n",
    "- Eg. for image classification, once we understand convolution, pooling, full connected layers, we can decide how many final layers we want to fine tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95261927-2f53-4630-9104-9d79e9332ec3",
   "metadata": {},
   "source": [
    "# Model debugging and testing\n",
    "\n",
    "- Launch the first version quickly and interate to improve it using real traffic.\n",
    "\n",
    "Debugging\n",
    "- Feature distribution change\n",
    "    - Real traffic data can change due to seasonality.\n",
    "- Feature logging issue\n",
    "    - Feature was computed differently during training and evaluation time.\n",
    "- Overfitting or underfitting\n",
    "- Missing important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296b590-9da8-448f-9000-5c48a0c7d91b",
   "metadata": {},
   "source": [
    "# Search ranking\n",
    "\n",
    "- Assume\n",
    "    - Billions of documents to search from.\n",
    "    - 10K quries per second.\n",
    "    \n",
    "## Metrics\n",
    "\n",
    "- Online metrics\n",
    "    - Click-through rate = # of clicks / # of impressions or views\n",
    "    - Sucessful session rate = # of successful sessions / # of total sessions\n",
    "        - Sucessful session is when users spend 10 seconds or longer viewing the page.\n",
    "    - Time to success (low number of queries per session)\n",
    "- Offline metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c09a8-a37f-4e4f-9174-dbf3f7751ce3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Search ranking\n",
    "\n",
    "### Scope\n",
    "- A general search enginer like Google.\n",
    "\n",
    "### Scale\n",
    "- How many websites to search from? Billions of documents.\n",
    "- How many requests per second? 10k queries per second.\n",
    "\n",
    "### Personalization\n",
    "- Assume user is logged in and historical search data of user is available.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "### Online metrics\n",
    "- Click through rate\n",
    "    - (number of clicks / number of impressions or views) \n",
    "    - Unsuccessful clicks would also be part of this metric.\n",
    "- Session success rate\n",
    "    - Dwell time: time user spent viewing a page.\n",
    "    - (number of sucessful sessions (dwell time > 10s) / number of total sessions)\n",
    "- Time to success\n",
    "    - Low number of quries means the system was good at guess what user wanted.\n",
    "\n",
    "### Offline metrics\n",
    "- Ground truth: actual outputs desired by the system. In this case, it is the rating provided by humans.\n",
    "- Assume the search engine returns documents $D_{1}, D_{2}, D_{3}, D_{4}$ in the order of relevance.\n",
    "- Assume human rates the documetns on scale of $0$ to $3$ ($3$ is highly relevant, $0$ is merely relevant) such that\n",
    "    - $D_{1} = 3$, $D_{2} = 2$, $D_{3} = 3$, $D_{4} = 0$ \n",
    "- Cumulative gain simply adds.\n",
    "    - $3+2+3+0 = 8$\n",
    "- Discounted cumulative gain (DCG) penalizes if highly relevant document appears lower in the result.\n",
    "    - $\\dfrac{3}{log_{2}(1+1)}+\\dfrac{2}{log_{2}(2+1)}+\\dfrac{3}{log_{2}(3+1)}+\\dfrac{0}{log_{2}(4+1)} = 3+1.262+1.5+0 = 5.762$\n",
    "- Normalized discounted cumulative gain (NDCG) is computed by (DCG / IDCG) where IDCG is DCG of ideal ordering.\n",
    "    - NDCG does not penalize irrelevant search result.\n",
    "    \n",
    "## Architecture\n",
    "\n",
    "<img src=\"img/search_engine1.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "### Layered model approach \n",
    "\n",
    "<img src=\"img/search_engine2.png\" style=\"width:1000px;height:200px;\">\n",
    "\n",
    "### Query rewriting\n",
    "- Queries are often poorly worded.\n",
    "- Increases recall. (return larger set of relevant results)\n",
    "\n",
    "Spell checker\n",
    "- Corrects spelling mistakes.\n",
    "\n",
    "Query expansion\n",
    "- Ex. expand \"restaurant\" to \"food\" or \"recipe\" to look for all candidates.\n",
    "\n",
    "### Query understanding\n",
    "- Intent behind query\n",
    "    - Ex. \"gas station\" has local intent.\n",
    "    - Ex. \"earthquake\" has newsy intent.\n",
    "    \n",
    "### Document selection\n",
    "- Select set of documents that are relevant to query.\n",
    "- Focused on recall. \n",
    "\n",
    "<img src=\"img/search_engine3.png\" style=\"width:400px;height:200px;\">\n",
    "\n",
    "Inverted index\n",
    "- Map words to documents.\n",
    "\n",
    "<img src=\"img/search_engine4.png\" style=\"width:600px;height:400px;\">\n",
    "\n",
    "Selection criteria\n",
    "- Go to index and retrive all documents based on this criteria.\n",
    "\n",
    "<img src=\"img/search_engine5.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "Scoring scheme\n",
    "\n",
    "<img src=\"img/search_engine6.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "Personalization measures searcher's profile such as age, gender, interest, location.\n",
    "\n",
    "### Ranker\n",
    "- Find best order of documents.\n",
    "- Stage 1 \n",
    "    - Find subset of document that should be passed to stage 2.\n",
    "    - Use simpler algorithm like linear regression to do binary classification.\n",
    "- Stage 2\n",
    "    - Perform complex algorithm like LambdaMART or LambdaRank to do document ordering.\n",
    "\n",
    "### Blender\n",
    "- Provides various results like posts, images, news, videos.\n",
    "- Avoid displaying results from a single or few sources.\n",
    "- Outputs final result page to users.\n",
    "\n",
    "### Filter \n",
    "\n",
    "- Filter inappropriate result despite good user engagement.\n",
    "\n",
    "## Training data generation\n",
    "- Takes online user data and generates positive and negative examples.\n",
    "\n",
    "Binary classification (pointwise approach)\n",
    "- Document is either relevant or irrevant.\n",
    "    - If user spent some time in the document, mark it relevant.\n",
    "    - If user immediate backed after clicking the document, mark it irrelevant.\n",
    "\n",
    "<img src=\"img/search_engine8.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Document ordering (pairwise approach)\n",
    "- The goal is to minimize inversion. (number of wrong orders compared to ground truth) \n",
    "- Rank the document based on user activity on each document and use that as training data.\n",
    "\n",
    "## Feature engineering\n",
    "\n",
    "<img src=\"img/search_engine7.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "Searcher (Assume the user is logged in)\n",
    "- Age\n",
    "- Gender\n",
    "- Interest\n",
    "\n",
    "Query\n",
    "- History\n",
    "    - For example, query \"earthquake\" historically was related to recent news.\n",
    "- Intent\n",
    "    - For example, query \"Pizza places\" has \"local\" intent, thus should give higher rank to pizza places located nearby the searcher.\n",
    "    \n",
    "Document\n",
    "- Page rank\n",
    "    - For example, the number of quality documents that link to it.\n",
    "- Radius\n",
    "    - For example, coffee shop in Toronto is relevant to people in 10km radicus but Eiffel tower has global scope.\n",
    "    \n",
    "Context\n",
    "- Time of day\n",
    "    - For example, query \"restaurant\" should consider restaurant open at the time of query.\n",
    "- Recent query\n",
    "    - Take a look at previous quries. For example, \"python\" -> \"python list\"  \n",
    "    \n",
    "Searcher-document\n",
    "- Distance\n",
    "    - For queries regarding locations, consider distance between searcher and matching location.\n",
    "- History\n",
    "    - For example, if searcher looked for video document in the past, then vidoe document would be more relevant to the searcher.\n",
    "    \n",
    "Query-document\n",
    "- Text match\n",
    "    - Matches in the title, metadata, content of document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f8179-cb97-4866-b156-976267e5f185",
   "metadata": {},
   "source": [
    "# 2. Twitter feed\n",
    "\n",
    "## Scope\n",
    "\n",
    "- Reverse chronological order fails to catch most engaging tweets due to the sheer large number of tweets.\n",
    "\n",
    "<img src=\"img/twitter_feed1.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "## Scale\n",
    "\n",
    "Assume\n",
    "- 500M daily active users.\n",
    "- 1 user is connected to 100 users.\n",
    "- User fetches the feed 10 times a day.\n",
    "\n",
    "<img src=\"img/twitter_feed2.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Positive user actions\n",
    "- Time spent viewing Tweets.\n",
    "- Liking Tweets.\n",
    "- Re-Tweeting.\n",
    "- Commenting on Tweets.\n",
    "\n",
    "Negative user actions\n",
    "- Hiding Tweets.\n",
    "- Reporting Tweets as inappropriate.\n",
    "\n",
    "<img src=\"img/twitter_feed3.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Weighted user actions\n",
    "- Not all actions are equal value.\n",
    "\n",
    "<img src=\"img/twitter_feed4.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "## Architecture\n",
    "\n",
    "<img src=\"img/twitter_feed5.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "### Tweet selection\n",
    "\n",
    "<img src=\"img/twitter_feed6.png\" style=\"width:500px;height:500px;\">\n",
    "\n",
    "Consider\n",
    "- Tweets generated from user's log out and log in.\n",
    "- Previous Tweets viewed by user, which was not popular but now is popular. \n",
    "\n",
    "<img src=\"img/twitter_feed7.png\" style=\"width:500px;height:500px;\">\n",
    "\n",
    "User comes back after a while\n",
    "- Need to fetch certain numbers of Tweets from a pool.\n",
    "\n",
    "<img src=\"img/twitter_feed8.png\" style=\"width:500px;height:500px;\">\n",
    "\n",
    "Tweets outside the user network\n",
    "- Aligns with user interests.\n",
    "- Locally/globally tredning.\n",
    "- Tweet is relevant to user's network.\n",
    "\n",
    "## Feature engineering\n",
    "\n",
    "<img src=\"img/twitter_feed9.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "User-author historical relations\n",
    "- author_liked_posts_3months: percentage of author Tweets user liked in the last 3 months.\n",
    "- author_liked_posts_count_1year: number of author Tweets user linke in the past one year.\n",
    "\n",
    "User-author similarity\n",
    "- common_followees: numbers of users and hash tags followed by both.\n",
    "- topic_similarity: similarity between hash tags in the posts that both interacted.\n",
    "- tweet_content_embedding_similarity: generate embedding (bag-of-words) for every user and take dot product between them.\n",
    "- social_embedding_similarity: every user is represented by bag-of-ids (rather than bag-of-words)\n",
    "\n",
    "Author influence\n",
    "- is_verified: if author is verified.\n",
    "- author_social_rank: similar to Google page rank.\n",
    "- author_num_followers: nubmer of followers that author has.\n",
    "- follower_to_following_ratio\n",
    "\n",
    "Author Tweets historical trend\n",
    "- author_engagement_rate_3months: (Tweets-interactions) / (Tweets-views)\n",
    "- author_topic_engagement_rate_3months: compute similar feature above but per topic.\n",
    "\n",
    "User-tweet\n",
    "- topic_similarity: similarity between hashtags and contents that user tweeted in the past and the tweet itself.\n",
    "\n",
    "Tweet content\n",
    "- Tweet_length: concise Tweet has higher chance of getting likes.\n",
    "- Tweet_recency:\n",
    "- is_image_video: Tweets with image or video are more catchy.\n",
    "- is_URL:\n",
    "\n",
    "Tweet interaction\n",
    "- num_total_interactions: need to use time decay model to give proper attention to trending Tweets.\n",
    "\n",
    "<img src=\"img/twitter_feed10.png\" style=\"width:500px;height:500px;\">\n",
    "\n",
    "## Training data generation\n",
    "\n",
    "<img src=\"img/twitter_feed11.png\" style=\"width:500px;height:500px;\">\n",
    "\n",
    "- Randomly downsample to match the number of positive and negative examples.\n",
    "- Train data on one time interval and validate data on next time interval.\n",
    "\n",
    "<img src=\"img/twitter_feed12.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "## Ranking\n",
    "\n",
    "- Given Tweets, predict probabilities of likes, comments, and re-Tweets.\n",
    "\n",
    "Logistic regression\n",
    "- Must create feature in training data manually. (Tree and NN are able to learn features)\n",
    "\n",
    "<img src=\"img/twitter_feed13.png\" style=\"width:700px;height:500px;\">\n",
    "\n",
    "Deep learning\n",
    "- Hyperparameters\n",
    "    - Learning rate.\n",
    "    - Number of hidden layers.\n",
    "    - Batch size.\n",
    "    - Number of epochs.\n",
    "    - Dropout rate.\n",
    "- Multi task NN where total_loss = like_loss + comment_loss + retweet_loss\n",
    "- Better than training sepearate network for each task because shared layers make training faster.\n",
    "\n",
    "<img src=\"img/twitter_feed14.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "<img src=\"img/twitter_feed15.png\" style=\"width:900px;height:900px;\">\n",
    "\n",
    "Stacking models\n",
    "- Ex. use Tree and NN to generate features to use in linear regression. \n",
    "\n",
    "<img src=\"img/twitter_feed16.png\" style=\"width:1000px;height:900px;\">\n",
    "\n",
    "## Diversity\n",
    "\n",
    "- Introduce penalty for same authors and similar content.\n",
    "    - For example, add negative score for repeated author and contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39302b3-7b61-4cdf-ab78-eee68c39eda5",
   "metadata": {},
   "source": [
    "# 3. Recommendation system\n",
    "\n",
    "## Scope\n",
    "\n",
    "- Give a user and context (time, location, etc) predict probability of engagement for each movie, and order movies.\n",
    "- Will use implicit feedback (user watched the movie or not) rathen explicit feedback (user rated the movie) to gather large training data.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Online\n",
    "- Engagement rate: (user clicked a movie / total number of sessions)\n",
    "- Videos watched: count videos user watch at least for some time.\n",
    "- Session watch time: overall time that user spent watching movies based on recommendation in a session.\n",
    "\n",
    "Offline\n",
    "- Mean Average Precision (mAP @ N)\n",
    "    - $AP@N = \\dfrac{1}{n}\\displaystyle\\sum_{k=1}^{N}P(k)rel(k)$\n",
    "    - $P(k)$ = precision up to $k$\n",
    "    - Precision = number of relevant recommendations / total number of recommendations\n",
    "    - rel(k) = whether $k^{th}$ item is relevant or not\n",
    "    - N = length of recommendation list\n",
    "    - m = number of movies relevant to user based on historical data\n",
    "\n",
    "- Mean Average Recall (mAR @ N)\n",
    "    - Recall = number of relevant recommendations / number of all movies\n",
    "    \n",
    "- F1 score = 2 * (mAP*mAR) / (mAP+mAR)\n",
    "\n",
    "## Architecture\n",
    "\n",
    "<img src=\"img/recommendation_system1.png\" style=\"width:1000px;height:700px;\">\n",
    "\n",
    "## Feature engineering\n",
    "\n",
    "<img src=\"img/recommendation_system2.png\" style=\"width:1000px;height:200px;\">\n",
    "\n",
    "User\n",
    "- age\n",
    "- gender\n",
    "- language\n",
    "- country\n",
    "- average_session_time\n",
    "- last_genre_watched\n",
    "- user_actor_histogram: histogram showing historical interaction between users and actors in movies.\n",
    "- user_genre_histogram\n",
    "- user_language_histogram\n",
    "\n",
    "Context\n",
    "- season_of_the_year\n",
    "- upcoming_holiday\n",
    "- days_to_upcoming_holiday\n",
    "- time_of_day\n",
    "- day_of_week\n",
    "- device\n",
    "\n",
    "Media\n",
    "- public-platform-rating\n",
    "- revenue\n",
    "- time_passed_since_release_date\n",
    "- time_on_platform\n",
    "- media_watch_history\n",
    "- genre\n",
    "- movie_duration\n",
    "- content_set_time_period\n",
    "- content_tags\n",
    "- show_season_number\n",
    "- country_of_origin\n",
    "- release_country\n",
    "- release_year\n",
    "- release_type\n",
    "- maturity_rating\n",
    "\n",
    "## Candidate generation\n",
    "\n",
    "- Select top $k$ movies to recommend to user.\n",
    "\n",
    "Collaborative filtering\n",
    "- Find users simialr to active user based on historical watches.\n",
    "\n",
    "<img src=\"img/recommendation_system3.png\" style=\"width:300px;height:300px;\">\n",
    "\n",
    "1. Nearest neighborhood\n",
    "\n",
    "<img src=\"img/recommendation_system4.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "- Consider $n$ by $m$ matrix of user $u_{i}$ and movie $m_{j}$\n",
    "- 1: user watched the movie.\n",
    "- 0: user ignored the movie.\n",
    "- empty: no impression yet.\n",
    "\n",
    "<img src=\"img/recommendation_system5.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "- Take is to predict the feedback for movies that users haven't watched.\n",
    "- Compute (for example) cosine similarity between user $i$ and other users, and select top $k$ similar users. (nearest neighbors)\n",
    "- Then, take weighted average of feedback from top $k$ similar users for movie $j$.\n",
    "\n",
    "2. Matrix factorization\n",
    "\n",
    "- Use latent vector $M$ such that\n",
    "    - User profile matrix $n$ by $M$.\n",
    "    - Media profile matrix $M$ by $m$. \n",
    "- Latent vector $M$ can be considered as features of users or movies.\n",
    "- Initialize user and movie vectors randomly. \n",
    "- For each known feedback value $f_{ij}$, predict feedback by taking dot product between user profile vertor $u_{i}$ and movie profile vector $m_{j}$. \n",
    "- Difference betweeen actual and predicted will be the error.\n",
    "    - $e_{ij} = f_{ij} - u{i} \\cdot m_{j}$\n",
    "- Use stochastic gradient descent to update user and movie latent vectors.\n",
    "\n",
    "<img src=\"img/recommendation_system6.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "Content-based filtering\n",
    "- Make recommendations based on content of media that user had already interacted with.\n",
    "\n",
    "## Training data generation\n",
    "\n",
    "- User watched 80% or more of the movie? positive example\n",
    "- User watched 10% or less of the movie? negative example\n",
    "- Between 10% and 80%? uncertain\n",
    "\n",
    "## Ranking\n",
    "\n",
    "- Probability of user watching a media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24775e36-102b-4e95-bbbb-e566b7987e5f",
   "metadata": {},
   "source": [
    "# 4. Self-driving car\n",
    "\n",
    "## Metric\n",
    "\n",
    "Intersection over union (IoU)\n",
    "- overlapping area / area of union\n",
    "- meanIoU is computed by taking average of IoU for each class. (building, road, sky, etc)\n",
    "\n",
    "## Architecture\n",
    "\n",
    "### Model\n",
    "\n",
    "## Training data generation\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57443de2-274d-440c-baec-cc84ebb7ff72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
