{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dea66ba-8414-4283-8e84-35ea932ae7bd",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "\n",
    "## Edge detection\n",
    "\n",
    "- ex. 6x6 image * (convolve) 3x3 filter = 4x4 image\n",
    "- vertical edge detection: use filters such as\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {1} & 0 & {1}\\\\\n",
    "  0  & 1 & 0 \\\\\n",
    "  {1} & 0 & {1}\n",
    "\\end{array}\\right)$\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {1} & 0 & {-1}\\\\\n",
    "  2  & 0 & -2 \\\\\n",
    "  {1} & 0 & {-1}\n",
    "\\end{array}\\right)$ (Sobel filter)\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {3} & 0 & {-3}\\\\\n",
    "  10  & 0 & -10 \\\\\n",
    "  {3} & 0 & {-3}\n",
    "\\end{array}\\right)$ (Schors filter)\n",
    "\n",
    "- vertical edge detection: use filters such as\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {1} & 1 & {1}\\\\\n",
    "  0  & 0 & 0 \\\\\n",
    "  {-1} & -1 & {-1}\n",
    "\\end{array}\\right)$\n",
    "\n",
    "- $n$ x $n * f$ x $f = (n-f+1)$ x $(n-f+1)$\n",
    "\n",
    "## Padding\n",
    "\n",
    "- avoids shrinking output and throwing away information from edges\n",
    "- $n$ x $n * f$ x $f = (n+2p-f+1)$ x $(n+2p-f+1)$\n",
    "- \"valid\": no padding\n",
    "- \"same\": pad so that output size is the same as the input size\n",
    "    - $p = \\dfrac{f-1}{2}$ ($f$ is usually odd)\n",
    "\n",
    "## Strided convolutions\n",
    "\n",
    "- $n$ x $n * f$ x $f = (\\dfrac{n+2p-f}{2}+1)$ x $(\\dfrac{n+2p-f}{2}+1)$\n",
    "\n",
    "## Convolution over volumn\n",
    "\n",
    "- 6x6x3 volumn (height x width x number of channels) * 3x3x3 volume (height x width x number of channels) = 4x4 (27 numbers are multiplied and summed up 16 times to produce 4x4)\n",
    "- number of channel must match between input and filter\n",
    "- multuple filters\n",
    "    - 6x6x3 * 3x3x3 (two of these: one for vertical edge and the other for horizontal edge) = 4x4x2\n",
    "    - $n$ x $n$ x $n_{c} * f$ x $f$ x $n_{c} = (n-f+1)$ x $(n-f+1)$ x $n_{c}^{'}$ where $n_{c}^{'}$ = number of filters\n",
    "    \n",
    "## One layer of a convolutional network\n",
    "\n",
    "- if layer $l$ is a convolutional layer\n",
    "    - $f^{l}$ = filter size\n",
    "    - $p^{l}$ = padding\n",
    "    - $s^{l}$ = stride\n",
    "    - $n_{c}^{l}$ = number of filters\n",
    "    - input: $n_{H}^{[l-1]}$ x $n_{W}^{[l-1]}$ x $n_{c}^{[l-1]}$\n",
    "    - output: $n_{H}^{[l]}$ x $n_{W}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - $n^{[l]} = \\lfloor\\dfrac{n^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}} + 1\\rfloor$\n",
    "    - each filter: $f^{[l]}$ x $f^{[l]}$ x $n_{c}^{[l-1]}$\n",
    "    - activation: $a^{[l]}$ => $n_{H}^{[l]}$ x $n_{W}^{[l]}$ x $n_{c}^{[l]}$ or $A^{[l]}$ => $m$ x $n_{H}^{[l]}$ x $n_{W}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - weights: $f^{[l]}$ x $f^{[l]}$ x $n_{c}^{[l-1]}$ x $n_{c}^{[l]}$\n",
    "    - bias: $n_{c}^{[l]}$ (represented as $(1,1,1,n_{c}^{[l]})$)\n",
    "    \n",
    "## Pooling layers\n",
    "\n",
    "- max pooling: take max number in each region\n",
    "- $f$: filter size\n",
    "- $s$: stride\n",
    "- no parameters to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f054b-d460-41d3-a593-9b14c3d1ea26",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- Convolution functions:\n",
    "    - Zero Padding\n",
    "    - Convolve window \n",
    "    - Convolution forward\n",
    "    - Convolution backward\n",
    "- Pooling functions:\n",
    "    - Pooling forward\n",
    "    - Create mask \n",
    "    - Distribute value\n",
    "    - Pooling backward\n",
    "    \n",
    "<img src=\"img/model.png\" style=\"width:800px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8b1cb-7303-47cc-85b9-165905e36806",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b19235-62d0-421c-942a-3d4ff3194604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1881c2-5af7-43d5-a8b2-d000026d422e",
   "metadata": {},
   "source": [
    "### Zero padding\n",
    "\n",
    "- Prevents width and height shrinking\n",
    "\n",
    "<img src=\"img/PAD.png\" style=\"width:600px;height:400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c640c4-094b-4ee3-b167-47dbb4ed8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_pad = np.pad(X, ((0,0), (pad, pad), (pad, pad), (0,0)), mode='constant', constant_values = (0,0))\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59470322-6b95-45ac-82f1-4da26919d0d5",
   "metadata": {},
   "source": [
    "### Convolve window\n",
    "\n",
    "- Takes an input volume \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another volume (usually of different size)\n",
    "\n",
    "<img src=\"img/Convolution_schematic.gif\" style=\"width:500px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e635a-7bc3-4a55-8c6a-6a6de4e8214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb604aca-389f-4436-abd6-4567bda2b88a",
   "metadata": {},
   "source": [
    "### Convolution forward\n",
    "\n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"img/conv_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "<img src=\"img/vert_horiz_kiank.png\" style=\"width:400px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29139b7-a78f-4bb1-bf7b-f33b8ee236bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above\n",
    "    n_H = int((n_H_prev - f + 2*pad) / stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2*pad) / stride) + 1\n",
    "    \n",
    "    # Initialize the output volume Z with zeros\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]               # Select ith training example's padded activation\n",
    "        \n",
    "        for h in range(n_H):           # loop over vertical axis of the output volume            \n",
    "            # Find the vertical start and end of the current \"slice\"\n",
    "            vert_start = stride*h\n",
    "            vert_end = stride*h + f\n",
    "           \n",
    "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\"\n",
    "                horiz_start = stride*w\n",
    "                horiz_end = stride*w + f\n",
    "                \n",
    "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron\n",
    "                    weights = W[:,:,:,c]\n",
    "                    biases = b[:,:,:,c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "                                        \n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a2abf-4376-44e6-bb62-3fba738a9095",
   "metadata": {},
   "source": [
    "### Convolution backward\n",
    "\n",
    "$$dA += \\sum _{h=0} ^{n_H} \\sum_{w=0} ^{n_W} W_c \\times dZ_{hw}$$\n",
    "\n",
    "$$dW_c  += \\sum _{h=0} ^{n_H} \\sum_{w=0} ^ {n_W} a_{slice} \\times dZ_{hw}$$\n",
    "\n",
    "$$db = \\sum_h \\sum_w dZ_{hw}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a51a1-3e8d-43c4-a60e-cb443e51a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
    "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
    "          numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
    "          numpy array of shape (1, 1, 1, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve information from \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
    "    dW = np.zeros((f, f, n_C_prev, n_C)) \n",
    "    db = np.zeros((1, 1, 1, n_C)) \n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :] \n",
    "        da_prev_pad = dA_prev_pad[i, :, :, :] \n",
    "        \n",
    "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):           # loop over the channels of the output volume\n",
    "                                     \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = stride*h\n",
    "                    vert_end = stride*h + f\n",
    "                    horiz_start = stride*w\n",
    "                    horiz_end = stride*w + f\n",
    "                                        \n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a6862-bcef-48d0-b612-e8ec4f779d10",
   "metadata": {},
   "source": [
    "### Pooling forward\n",
    "\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "\n",
    "$$ n_C = n_{C_{prev}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022baf1e-106a-4169-b815-c56ac8a1b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\"\n",
    "            vert_start = stride*h\n",
    "            vert_end = stride*h + f\n",
    "            \n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\"\n",
    "                horiz_start = stride*w\n",
    "                horiz_end = stride*w + f\n",
    "                \n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "\n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76680d0-9586-4222-9e61-93981800fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    \"\"\"\n",
    "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- Array of shape (f, f)\n",
    "    \n",
    "    Returns:\n",
    "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = x == np.max(x)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b76959-7a6d-4bbd-8a6a-f6754be21189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \"\"\"\n",
    "    Distributes the input value in the matrix of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- input scalar\n",
    "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
    "    \n",
    "    Returns:\n",
    "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from shape (≈1 line)\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix (≈1 line)\n",
    "    average = dz / (n_W*n_H)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
    "    a = np.full((n_W, n_H), average)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9471c75-1a3e-49e0-9df0-4e4cc433f949",
   "metadata": {},
   "source": [
    "### Pooling backward\n",
    "\n",
    "$$ dZ = 1 \\quad \\rightarrow  \\quad dZ =\\begin{bmatrix}\n",
    "1/4 && 1/4 \\\\\n",
    "1/4 && 1/4\n",
    "\\end{bmatrix}\\tag{5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9b133-18a5-4bf9-8379-9b40ef379cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the backward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
    "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve information from cache (≈1 line)\n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "    # Initialize dA_prev with zeros (≈1 line)\n",
    "    dA_prev = np.zeros(A_prev.shape)\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select training example from A_prev (≈1 line)\n",
    "        a_prev = A_prev[i,:,:,:]\n",
    "        \n",
    "        for h in range(n_H):                   # loop on the vertical axis\n",
    "            for w in range(n_W):               # loop on the horizontal axis\n",
    "                for c in range(n_C):           # loop over the channels (depth)\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = stride*h\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = stride*w\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    if mode == \"max\":\n",
    "                        \n",
    "                        # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        # Create the mask from a_prev_slice (≈1 line)\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask, dA[i, h, w, c]) \n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        \n",
    "                        # Get the value a from dA (≈1 line)\n",
    "                        da = dA[i, h, w, c]\n",
    "                        # Define the shape of the filter as fxf (≈1 line)\n",
    "                        shape = (f,f)\n",
    "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] +=  distribute_value(da, shape)\n",
    "                        \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf460a-af45-4f30-a5a4-e7eee234617a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
