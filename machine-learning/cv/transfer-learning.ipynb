{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83042dee-a399-4c2f-ab30-510c8d14460f",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "## Neural style transfer\n",
    "\n",
    "- content image (C), style image (S), generated image (G)\n",
    "- cost function $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$\n",
    "- initialize $G$ randomly\n",
    "- use gradient descent to minimize $J(G)$\n",
    "    - $G = G - \\dfrac{\\partial}{\\partial G}J(G)$\n",
    "    \n",
    "## Content cost function\n",
    "\n",
    "- say you use hidden layer $l$ to compute content cost\n",
    "- use pre-trained ConvNet (eg. VGG network)\n",
    "- let $a^{[l](C)}$ and $a^{[l](G)}$ be the activation of layer $l$ on the images\n",
    "- if $a^{[l](C)}$ and $a^{[l](G)}$ are similar, both images have similar content\n",
    "    - $J_{content}(C,G) = \\dfrac{1}{2}||a^{[l](C)} - a^{[l](G)}||^{2}$\n",
    "    \n",
    "## Style cost function\n",
    "\n",
    "- style matrix\n",
    "    - let $a_{i,j,k}^{l}$ = activation at $(i,j,k)$ (height, weight, channel)\n",
    "    - $G^{[l]}$ is $n_{c}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - $G_{kk'}^{[l]} = \\displaystyle\\sum_{i=1}^{n_{H}^{[l]}}\\displaystyle\\sum_{j=1}^{n_{W}^{[l]}}a_{ijk}^[l]a_{ijk'}^[l]$ (do this for both style and generated) \n",
    "    - $J_{style}^{[l]}(S,G) = ||G^{[l](S)} - G^{[l](G)}||^{2}_{F} = \\displaystyle\\sum_{k}\\displaystyle\\sum_{k'}(G_{kk'}^{[l](S)} - G_{kk'}^{[l](G)})^{2}$ \n",
    "    - $J_{style}(S,G) = \\displaystyle\\sum_{l}\\lambda^{[l]}J_{style}^{[l]}(S,G)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107192d4-6b67-48df-8e3e-341e565a2f13",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- Merges two images (content and style) to create a new image. (generated)\n",
    "\n",
    "<img src=\"img/louvre_generated.png\" style=\"width:750px;height:200px;\">\n",
    "\n",
    "<img src=\"img/perspolis_vangogh.png\" style=\"width:750px;height:300px;\">\n",
    "\n",
    "<img src=\"img/pasargad_kashi.png\" style=\"width:750px;height:300px;\">\n",
    "\n",
    "<img src=\"img/circle_abstract.png\" style=\"width:750px;height:300px;\">\n",
    "\n",
    "Neural style transfer\n",
    "- Build the content cost function $J_{content}(C,G)$\n",
    "- Build the style cost function $J_{style}(S,G)$\n",
    "- Put it together to get $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a219c85-d100-4df4-b552-5640ded1c5a6",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f15d7-33b0-4865-b3a4-3da0c3f66f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8c1a7-fc2e-4a35-9ca0-173fa3c1c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 400\n",
    "    IMAGE_HEIGHT = 300\n",
    "    COLOR_CHANNELS = 3\n",
    "    NOISE_RATIO = 0.6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3)) \n",
    "    VGG_MODEL = 'pretrained-model/imagenet-vgg-verydeep-19.mat' # Pick the VGG 19-layer model by from the paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".\n",
    "    STYLE_IMAGE = 'images/stone_style.jpg' # Style image to use.\n",
    "    CONTENT_IMAGE = 'images/content300.jpg' # Content image to use.\n",
    "    OUTPUT_DIR = 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bf307-7017-4fcd-b5b5-e098b2576ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is stored in a python dictionary.  \n",
    "# The python dictionary contains key-value pairs for each layer.  \n",
    "# The 'key' is the variable name and the 'value' is a tensor for that layer. \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "model = load_vgg_model(\"data/imagenet-vgg-verydeep-19.mat\")\n",
    "pp.pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80f939-4035-4f6f-b63f-04487be04f9c",
   "metadata": {},
   "source": [
    "### Compute content cost\n",
    "\n",
    "- We want \"G\" to be similar to \"C\".\n",
    "- Choosing middle layer in network gets the best result in pracice.\n",
    "\n",
    "#### Forward prop \"C\"\n",
    "\n",
    "- Set \"C\" as the input to pretrained VGG, and run forward prop.\n",
    "- $a^{(C)}$ be the activation in the chosen layer. ($n_H \\times n_W \\times n_C$ tensor_\n",
    "\n",
    "#### Forward prop \"G\"\n",
    "\n",
    "- Set \"G\" as the input to pretrained VGG, and run forward prop.\n",
    "- Let $a^{(G)}$ be the corresponding activation. \n",
    "\n",
    "$$J_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2$$\n",
    "\n",
    "<img src=\"img/NST_LOSS.png\" style=\"width:800px;height:400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54d69a0-c6a7-47a7-aaf3-b2619aeda0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_content -- scalar that you compute using equation 1 above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # Reshape a_C and a_G (≈2 lines)\n",
    "    a_C_unrolled = tf.reshape(a_C, [m, tf.multiply(n_H, n_W), n_C])\n",
    "    a_G_unrolled = tf.reshape(a_G, [m, tf.multiply(n_H, n_W), n_C])\n",
    "    \n",
    "    # compute the cost with tensorflow (≈1 line)\n",
    "    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled))) / (4 * n_H * n_W * n_C)\n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255c77d-1f34-4dbf-8eda-9b6d9f5d5caa",
   "metadata": {},
   "source": [
    "### Compute style cost\n",
    "\n",
    "#### Style matric (Gram matrix)\n",
    "\n",
    "- ${\\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j})  }$.\n",
    "- Measures how similar $v_i$ is to $v_j$ .\n",
    "\n",
    "<img src=\"img/NST_GM.png\" style=\"width:900px;height:300px;\">\n",
    "$$\\mathbf{G}_{gram} = \\mathbf{A}_{unrolled} \\mathbf{A}_{unrolled}^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca25842d-0178-431d-abc7-544f41079bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (n_C, n_H*n_W)\n",
    "    \n",
    "    Returns:\n",
    "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    GA = tf.matmul(A, tf.transpose(A))\n",
    "    \n",
    "    return GA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce1614-4f54-47f4-905a-0b39ab16cde7",
   "metadata": {},
   "source": [
    "#### Style cost\n",
    "\n",
    "$$J_{style}^{[l]}(S,G) = \\frac{1}{4 \\times {n_C}^2 \\times (n_H \\times n_W)^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfab15ab-ea57-4760-b800-a0d229fb5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
    "    #a_S = tf.reshape(a_S, [n_C, tf.multiply(n_H, n_W)])\n",
    "    #a_G = tf.reshape(a_G, [n_C, tf.multiply(n_H, n_W)])\n",
    "    a_S = tf.transpose(tf.reshape(a_S, [tf.multiply(n_H, n_W), n_C]))\n",
    "    a_G = tf.transpose(tf.reshape(a_G, [tf.multiply(n_H, n_W), n_C]))\n",
    "\n",
    "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "\n",
    "    # Computing the loss (≈1 line)\n",
    "    #print(tf.reduce_sum(tf.square(tf.subtract(GS, GG))).eval())\n",
    "    \n",
    "    J_style_layer = tf.reduce_sum(tf.square(tf.subtract(GS, GG))) / (4*n_H*n_W*n_H*n_W*n_C*n_C)\n",
    "    \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fb73b-b047-4506-9f52-071f6f41e302",
   "metadata": {},
   "source": [
    "#### Style weights\n",
    "\n",
    "$$J_{style}(S,G) = \\sum_{l} \\lambda^{[l]} J^{[l]}_{style}(S,G)$$\n",
    "\n",
    "where $\\lambda^{[l]}$ is `STYLE_LAYERS`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa2b0b3-35f3-44ca-9283-d564611cf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4259c2c2-174a-47f5-8571-b1a0c16c3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    model -- our tensorflow model\n",
    "    STYLE_LAYERS -- A python list containing:\n",
    "                        - the names of the layers we would like to extract style from\n",
    "                        - a coefficient for each of them\n",
    "    \n",
    "    Returns: \n",
    "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    J_style = 0\n",
    "\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = model[layer_name]\n",
    "\n",
    "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
    "        a_S = sess.run(out)\n",
    "\n",
    "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n",
    "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
    "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
    "        a_G = out\n",
    "        \n",
    "        # Compute style_cost for the current layer\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "\n",
    "        # Add coeff * J_style_layer of this layer to overall style cost\n",
    "        J_style += coeff * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c2746-b20f-4ec5-8b81-7f21b04993c8",
   "metadata": {},
   "source": [
    "### Total cost\n",
    "\n",
    "$$J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3a30ee-e09a-494c-8f83-6896608e5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost function\n",
    "    \n",
    "    Arguments:\n",
    "    J_content -- content cost coded above\n",
    "    J_style -- style cost coded above\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost as defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    J = alpha * J_content + beta * J_style\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a2407-8f93-4a24-bf49-6c410a4c5874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
