{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83042dee-a399-4c2f-ab30-510c8d14460f",
   "metadata": {},
   "source": [
    "## Neural style transfer\n",
    "\n",
    "- content image (C), style image (S), generated image (G)\n",
    "- cost function $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$\n",
    "- initialize $G$ randomly\n",
    "- use gradient descent to minimize $J(G)$\n",
    "    - $G = G - \\dfrac{\\partial}{\\partial G}J(G)$\n",
    "    \n",
    "## Content cost function\n",
    "\n",
    "- say you use hidden layer $l$ to compute content cost\n",
    "- use pre-trained ConvNet (eg. VGG network)\n",
    "- let $a^{[l](C)}$ and $a^{[l](G)}$ be the activation of layer $l$ on the images\n",
    "- if $a^{[l](C)}$ and $a^{[l](G)}$ are similar, both images have similar content\n",
    "    - $J_{content}(C,G) = \\dfrac{1}{2}||a^{[l](C)} - a^{[l](G)}||^{2}$\n",
    "    \n",
    "## Style cost function\n",
    "\n",
    "- style matrix\n",
    "    - let $a_{i,j,k}^{l}$ = activation at $(i,j,k)$ (height, weight, channel)\n",
    "    - $G^{[l]}$ is $n_{c}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - $G_{kk'}^{[l]} = \\displaystyle\\sum_{i=1}^{n_{H}^{[l]}}\\displaystyle\\sum_{j=1}^{n_{W}^{[l]}}a_{ijk}^[l]a_{ijk'}^[l]$ (do this for both style and generated) \n",
    "    - $J_{style}^{[l]}(S,G) = ||G^{[l](S)} - G^{[l](G)}||^{2}_{F} = \\displaystyle\\sum_{k}\\displaystyle\\sum_{k'}(G_{kk'}^{[l](S)} - G_{kk'}^{[l](G)})^{2}$ \n",
    "    - $J_{style}(S,G) = \\displaystyle\\sum_{l}\\lambda^{[l]}J_{style}^{[l]}(S,G)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107192d4-6b67-48df-8e3e-341e565a2f13",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- Merges two images (content and style) to create a new image. (generated)\n",
    "\n",
    "<img src=\"img/louvre_generated.png\" style=\"width:750px;height:200px;\">\n",
    "\n",
    "Neural style transfer\n",
    "- Build the content cost function $J_{content}(C,G)$\n",
    "- Build the style cost function $J_{style}(S,G)$\n",
    "- Put it together to get $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a219c85-d100-4df4-b552-5640ded1c5a6",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f15d7-33b0-4865-b3a4-3da0c3f66f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8c1a7-fc2e-4a35-9ca0-173fa3c1c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 400\n",
    "    IMAGE_HEIGHT = 300\n",
    "    COLOR_CHANNELS = 3\n",
    "    NOISE_RATIO = 0.6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3)) \n",
    "    VGG_MODEL = 'pretrained-model/imagenet-vgg-verydeep-19.mat' # Pick the VGG 19-layer model by from the paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition\".\n",
    "    STYLE_IMAGE = 'images/stone_style.jpg' # Style image to use.\n",
    "    CONTENT_IMAGE = 'images/content300.jpg' # Content image to use.\n",
    "    OUTPUT_DIR = 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bf307-7017-4fcd-b5b5-e098b2576ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is stored in a python dictionary.  \n",
    "# The python dictionary contains key-value pairs for each layer.  \n",
    "# The 'key' is the variable name and the 'value' is a tensor for that layer. \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "model = load_vgg_model(\"data/imagenet-vgg-verydeep-19.mat\")\n",
    "pp.pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80f939-4035-4f6f-b63f-04487be04f9c",
   "metadata": {},
   "source": [
    "### Compute content cost\n",
    "\n",
    "- We want \"G\" to be similar to \"C\".\n",
    "- Choosing middle layer in network gets the best result in pracice.\n",
    "\n",
    "#### Forward prop \"C\"\n",
    "\n",
    "- Set \"C\" as the input to pretrained VGG, and run forward prop.\n",
    "- $a^{(C)}$ be the activation in the chosen layer. ($n_H \\times n_W \\times n_C$ tensor_\n",
    "\n",
    "#### Forward prop \"G\"\n",
    "\n",
    "- Set \"G\" as the input to pretrained VGG, and run forward prop.\n",
    "- Let $a^{(G)}$ be the corresponding activation. \n",
    "\n",
    "$$J_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2$$\n",
    "\n",
    "<img src=\"img/NST_LOSS.png\" style=\"width:800px;height:400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54d69a0-c6a7-47a7-aaf3-b2619aeda0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_content -- scalar that you compute using equation 1 above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from a_G (≈1 line)\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    # Reshape a_C and a_G (≈2 lines)\n",
    "    a_C_unrolled = tf.reshape(a_C, [m, tf.multiply(n_H, n_W), n_C])\n",
    "    a_G_unrolled = tf.reshape(a_G, [m, tf.multiply(n_H, n_W), n_C])\n",
    "    \n",
    "    # compute the cost with tensorflow (≈1 line)\n",
    "    J_content = tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled))) / (4 * n_H * n_W * n_C)\n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255c77d-1f34-4dbf-8eda-9b6d9f5d5caa",
   "metadata": {},
   "source": [
    "### Computer style cost\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
