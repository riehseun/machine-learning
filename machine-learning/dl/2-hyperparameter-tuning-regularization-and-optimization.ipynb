{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / dev / test sets\n",
    "\n",
    "- train on train set\n",
    "- see which model performs the best on dev set\n",
    "- evaluate your best model on test set\n",
    "- dev and test set must come from the same distribution\n",
    "- not having test set might be okay\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td>train set error</td>\n",
    "    <td>1%</td>\n",
    "    <td>15%</td>\n",
    "    <td>15%</td>\n",
    "    <td>0.5%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>test set error</td>\n",
    "    <td>11%</td>\n",
    "    <td>16%</td>\n",
    "    <td>30%</td>\n",
    "    <td>1%</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "    <td>means</td>\n",
    "    <td>variance</td>\n",
    "    <td>bias</td>\n",
    "    <td>both bias and variance</td>\n",
    "    <td>neither</td>\n",
    "</tr>    \n",
    "</table>\n",
    "\n",
    "- if bias? use bigger network, train longer\n",
    "- if variance? get more data, use regularization\n",
    "\n",
    "## Regularization\n",
    "\n",
    "- penalizes weights being large\n",
    "- $J(w,b) = \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}L(\\hat{y}^{(i)}, y^{(i))}) + \\dfrac{\\lambda}{2m}||w||^{2}$\n",
    "- where $||w||^{2} = \\displaystyle\\sum_{j=1}^{n_{x}}w_{j}^{2} = w^{T}w$\n",
    "\n",
    "In general\n",
    "- $J(w^{[1]},b^{[1]} \\dots w^{[2]},b^{[2]}) = \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}L(\\hat{y}^{(i)}, y^{(i))}) + \\dfrac{\\lambda}{2m}\\displaystyle\\sum_{l=1}^{L}||w^{[l]}||_{F}^{2}$\n",
    "- where $||w^{[l]}||_{F}^{2} = \\displaystyle\\sum_{i=1}^{n^{[l-1]}}\\displaystyle\\sum_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^{2}$\n",
    "- add $\\dfrac{\\lambda}{m}w^{[l]}$ to $dw^{[l]}$\n",
    "- $w^{[l]} = w^{[l]} - \\alpha dw^{[l]}$ remains the same\n",
    "\n",
    "## Dropout\n",
    "\n",
    "Example: $l =3$\n",
    "- keep_prop = 0.8 (20% chance that units will be shutdown)\n",
    "- d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep_prop\n",
    "- a3 = np.multiply(a3, d3)\n",
    "- a3 = a3 / keep_prop\n",
    "\n",
    "Other regularization\n",
    "- data augmentation\n",
    "- early stopping\n",
    "\n",
    "## Normalizing inputs\n",
    "\n",
    "- to make gradient descent faster \n",
    "- applies to both training and test sets\n",
    "- $\\mu = \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}x^{(i)}$, $\\sigma^{2} = \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}x^{(i)}**2$\n",
    "- $x = \\dfrac{x-\\mu}{\\sigma}$\n",
    "\n",
    "## Vanishing/exploding gradient\n",
    "\n",
    "- happens in deep neural network\n",
    "- to partially overcome, weight initialization\n",
    "    - Var$(w_{i})$ = $\\dfrac{1}{n}$ or $\\dfrac{2}{n}$ (good for RELU)\n",
    "    - $w^{[l]}$ = np.random.randn() * init_factor\n",
    "    - init_factor = np.sqrt$\\left(\\dfrac{2}{n^{[l-1]}}\\right)$ (good for RELU) or np.sqrt$\\left(\\dfrac{1}{n^{[l-1]}}\\right)$ (Xavier initialization)\n",
    "    \n",
    "## Gradient checking\n",
    "\n",
    "- take $w^{[1]},b^{[1]} \\dots w^{[l]},b^{[l]}$ and reshape into a big factor $\\theta$\n",
    "    - $J(w^{[1]},b^{[1]} \\dots w^{[l]},b^{[l]}) J(\\theta)$\n",
    "- take $dw^{[1]},db^{[1]} \\dots dw^{[l]},db^{[l]}$ and reshape into a big factor $d\\theta$\n",
    "- for each $i$\n",
    "    - $d\\theta_{approx}[i] = \\dfrac{J(\\theta_{1}, \\theta_{2} \\dots \\theta_{i+\\epsilon} \\dots) - J(\\theta_{1}, \\theta_{2} \\dots \\theta_{i-\\epsilon} \\dots)}{2\\epsilon} \\approx \\partial \\theta[i] = \\dfrac{\\partial J}{\\partial \\theta_{i}}$\n",
    "- check\n",
    "    - $\\dfrac{||d\\theta_{approx}-d\\theta||_{2}}{||d\\theta_{approx}||_{2} + ||d\\theta||_{2}} \\approx 10^{-7}$ good \n",
    "    - bigger than $10^{-3}$ means something wrong!\n",
    "- don't use in training, only to debug\n",
    "- include regularization term in $d\\theta$ calculation\n",
    "- doesn't work with dropout (you can grad check with keep_prop=1.0, then later turn on dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch gradient descent\n",
    "\n",
    "- in one epoc, min-batch gradient descent take $nb$ gradient descents rather than 1 (Batch gradient descent)\n",
    "- let batch_size = $bs$\n",
    "- let number_of_batches = $nb$\n",
    "- $x^{\\{t\\}}$: $(n_{x}, bs)$, $y^{\\{t\\}}$: $(1, bs)$\n",
    "\n",
    "Implementation\n",
    "- for $t = 1 \\dots nb$\n",
    "    - forward prop on $x^{\\{t\\}}$\n",
    "        - $Z^{[1]} = w^{[1]}X^{\\{t\\}} + b^{[1]}$\n",
    "        - $A^{[1]} = g^{[1]}(Z^{[1]})$\n",
    "        - $ \\vdots $\n",
    "        - $A^{[L]} = g^{[L]}(Z^{[L]})$\n",
    "    - compute cost \n",
    "        - $J^{\\{t\\}} = \\dfrac{1}{bs}\\displaystyle\\sum_{i=1}^{l}L(\\hat{y}^{(i)}, y^{(i)}) + \\dfrac{\\lambda}{2bs}\\displaystyle\\sum_{l}||w^{[l]}||_{F}^{2}$\n",
    "    - backward prop to compute gradients w.r.t. $J^{\\{t\\}}$ (use $X^{\\{t\\}}, y^{\\{t\\}}$) \n",
    "    - $w^{[l]} = w^{[l]} - \\alpha dw^{[l]}$\n",
    "    - $b^{[l]} = b^{[l]} - \\alpha db^{[l]}$\n",
    "   \n",
    "Notes   \n",
    "- batch size = $m$: batch gradient (takes too long per iteration)\n",
    "- batch size = 1: stochastic gradient (loses speed up from vectorization)\n",
    "- typical min-batch sizes are 64, 128, 256, 512, 1024\n",
    "\n",
    "## Exponentially weighted average (moving average)\n",
    "\n",
    "- $V_{t} = \\beta V_{t} + (1-\\beta)\\theta_{t}$\n",
    "    - approximately averges over $\\dfrac{1}{1-\\beta} data$\n",
    "    \n",
    "Implement\n",
    "- $V = 0$\n",
    "    - repeat\n",
    "        - compute $\\theta_{t}$\n",
    "        - $V_{\\theta} = \\beta V_{\\theta} + (1-\\beta)\\theta_{t}$\n",
    "        \n",
    "## Momentum\n",
    "\n",
    "- reduce oscilation by slowing learning vertially but speeding up learning horizontally\n",
    "- init $V_{dw} = 0, V_{db} = 0$\n",
    "- on iteration $t$\n",
    "    - compute $dw, db$ on current min-batch\n",
    "    - $V_{dw} = \\beta V_{dw} + (1-\\beta)dw$\n",
    "    - $V_{db} = \\beta V_{db} + (1-\\beta)db$\n",
    "    - $w = w - \\alpha V_{dw}$\n",
    "    - $b = b - \\alpha V_{db}$\n",
    "- $\\beta$ is usually set to 0.9\n",
    "\n",
    "## RMSprop\n",
    "\n",
    "- on iteration $t$\n",
    "    - compute $dw, db$ on current min-batch\n",
    "    - $S_{dw} = \\beta S_{dw} + (1-\\beta)dw^{2}$\n",
    "    - $S_{db} = \\beta S_{db} + (1-\\beta)db^{2}$\n",
    "    - $w = w - \\alpha \\dfrac{dw}{\\sqrt{S_{dw}}}$\n",
    "    - $b = b - \\alpha \\dfrac{db}{\\sqrt{S_{db}}}$\n",
    "    \n",
    "## Adam (Adaptive moment estimation)\n",
    "\n",
    "- init $V_{dw} = 0, V_{db} = 0, S_{dw} = 0, S_{db} = 0$\n",
    "- on iteration $t$\n",
    "    - compute $dw, db$ on current min-batch\n",
    "    - $V_{dw} = \\beta_{1} V_{dw} + (1-\\beta_{1})dw$\n",
    "    - $V_{db} = \\beta_{1} V_{db} + (1-\\beta_{1})db$\n",
    "    - $S_{dw} = \\beta_{2} S_{dw} + (1-\\beta_{2})dw^{2}$\n",
    "    - $S_{db} = \\beta_{2} S_{db} + (1-\\beta_{2})db^{2}$\n",
    "    - $V_{dw,corrected} = \\dfrac{V_{dw}}{(1-\\beta_{1}^{t})}$\n",
    "    - $V_{db,corrected} = \\dfrac{V_{db}}{(1-\\beta_{1}^{t})}$\n",
    "    - $S_{dw,corrected} = \\dfrac{S_{dw}}{(1-\\beta_{2}^{t})}$\n",
    "    - $S_{db,corrected} = \\dfrac{S_{db}}{(1-\\beta_{2}^{t})}$\n",
    "    - $w = w - \\alpha \\dfrac{V_{dw,corrected}}{\\sqrt{S_{dw,corrected}}+\\epsilon}$\n",
    "    - $b = b - \\alpha \\dfrac{V_{db,corrected}}{\\sqrt{S_{db,corrected}}+\\epsilon}$\n",
    "- usually $\\beta_{1} = 0.9$, $\\beta_{2} = 0.900$, $\\epsilon = 10^{-8}$\n",
    "\n",
    "## Learning rate decay\n",
    "\n",
    "- helps gradient descent converge by taking smaller steps as it approaches the minimum\n",
    "- for example,\n",
    "    - let decay rate = dr\n",
    "    - let epoch number = en\n",
    "    - $\\alpha = \\dfrac{1}{1+dr*en} * \\alpha_{0}$\n",
    "    \n",
    "## Local optima\n",
    "\n",
    "- in high dimensions, when gradient is 0, it is almost always saddle points rather than local optima (so it is unlikely for the optimization algorithm to stuck at bad local optima)\n",
    "- plateaus (where derivatives are close to 0) can slow down the learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "- should use random sampling to choose the number of layers, number of features, etc\n",
    "- scale parameters accordingly\n",
    "    - for example, $\\alpha = 0.0001 \\dots 1$\n",
    "        - use log scale such that $0.0001, 0.001, 0.01, 0.1, 1$\n",
    "    - for example, $\\beta = 0.9 \\dots 0.999$\n",
    "        - use $1-\\beta$ such that $0.1, 0.01, 0.001$\n",
    "- panda: babysit one model\n",
    "- caviar: train many models in parallel\n",
    "\n",
    "## Batch nomralization\n",
    "\n",
    "- normalize activations \n",
    "    - given some intermediate values in neural network $z^{(1)} \\dots z^{(m)}$\n",
    "    - $\\mu = \\dfrac{1}{m}\\displaystyle\\sum_{i}z^{(i)}$\n",
    "    - $\\sigma = \\dfrac{1}{m}\\displaystyle\\sum_{i}(z_{i}-\\mu)^{2}$\n",
    "    - $z_{norm}^{(i)} = \\dfrac{z^{(i)}-\\mu}{\\sqrt{\\sigma^{2}+\\epsilon}}$\n",
    "    - $\\tilde{z}^{(i)} = \\gamma z_{norm}^{(i)} + \\beta$\n",
    "- for example, if $\\gamma = \\sqrt{\\sigma^{2}+\\epsilon}, \\beta = \\mu$, then $z_{norm}^{(i)} = \\tilde{z}^{(i)}$\n",
    "- use $\\tilde{z}^{(i)}$ instead of ${z}^{(i)}$ \n",
    "- but unlike inputs, you don't want to force activation to be ~ $N(0,1)$\n",
    "\n",
    "$X \\xrightarrow{w^{[1]}, b^{[1]}} z^{[1]} \\xrightarrow{\\beta^{[1]}, \\gamma^{[1]}} \\tilde{z}^{[1]} \\rightarrow a^{[1]} = g^{[1]}(\\tilde{z}^{[1]}) \\xrightarrow{w^{[2]}, b^{[2]}} z^{[2]} \\xrightarrow{\\beta^{[2]}, \\gamma^{[2]}} \\tilde{z}^{[2]} \\rightarrow a^{[2]} \\rightarrow \\dots$ \n",
    "- parameters: $w, b, \\beta, \\gamma$\n",
    "\n",
    "Working with mini-batches\n",
    "- parameters: $w, \\beta, \\gamma$ (no need for $b$)\n",
    "- $z^{[l]} = w^{[l]}a^{[l-1]}$\n",
    "- $\\tilde{z}^{[l]} = \\gamma^{[l]}z_{norm}^{[l]} + \\beta^{[l]}$\n",
    "- for $t = 1 \\dots$ num_mini_batches\n",
    "    - compute forward prop on $X^{\\{t\\}}$ \n",
    "        - in each layer, use BN to replace $z^{[l]}$ with $\\tilde{z}^{[l]}$\n",
    "    - use backprop to compute $dw^{[l]}, d\\beta^{[l]}, d\\gamma^{[l]}$ (no need for $db^{[l]}$)\n",
    "    - update $w^{[l]} = w^{[l]} - \\alpha dw^{[l]}, \\beta^{[l]} = \\beta^{[l]} - \\alpha d\\beta^{[l]}, \\gamma^{[l]} = \\gamma^{[l]} - \\alpha d\\gamma^{[l]}$\n",
    "    \n",
    "Batch normalization as regularization\n",
    "- each mini-batch is scaled by mean/variance computed on just that mini-batchj\n",
    "- this adds some noise to $z^{[l]}$\n",
    "- this has slight regularization effect\n",
    "\n",
    "Batch normalization as test time\n",
    "- $\\mu, \\sigma^{2}$: estimate using exponentially weighted average (across mini-batches)\n",
    "- $X^{\\{1\\}} \\rightarrow \\mu^{\\{1\\}[l]}, \\sigma^{\\{1\\}[l]}, X^{\\{2\\}} \\rightarrow \\mu^{\\{2\\}[l]}, \\sigma^{\\{1\\}[2]}, X^{\\{3\\}} \\rightarrow \\mu^{\\{3\\}[l]}, \\sigma^{\\{3\\}[l]}, \\dots$\n",
    "\n",
    "## Softmax regression\n",
    "\n",
    "- let $C$ be number of classes\n",
    "- last layer (softwax layer) has $n^{[L]}= C$ units\n",
    "    - $z^{[L]} = w^{[L]}a^{[L-1]} + b^{[L]}$\n",
    "    - $t = e^{(z^{[L]})}$\n",
    "    - $a^{[L]} = \\dfrac{e^{(z^{[L]})}}{\\displaystyle\\sum_{j}t_{i}}, a_{i}^{[L]} = \\dfrac{t_{i}}{\\displaystyle\\sum_{j}t_{i}}$\n",
    "- softmax regression generalizes logistic regression to $C$ classes\n",
    "- loss function\n",
    "    - $L(\\hat{y}, y) = -\\displaystyle\\sum_{j}y_{j}log\\hat{y}_{j}$\n",
    "- cost function\n",
    "    - $J(w^{[1]}, b^{[1]}, \\dots) = \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}L(\\hat{y}^{(i)}, y^{(i)})$\n",
    "    \n",
    "$z^{[L]} \\rightarrow a^{[L]} = \\hat{y} \\rightarrow L(\\hat{y}, y)$\n",
    "- backprod: $dz^{[L]} = \\hat{y} - y$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
