{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring Machine Learning Projects\n",
    "\n",
    "## Introduction to ML strategy\n",
    "\n",
    "### Orthogonalization\n",
    "\n",
    "- Fit training set well on cost function. (bigger network, better optimization algorithm)\n",
    "- Then, fit dev set well on cost function. (regularization, bigger training set)\n",
    "- Then, fit test set well on cost function. (bigger dev set)\n",
    "- Then, perform well in real world. (change dev set or cost function)\n",
    "\n",
    "## Setting up your goal\n",
    "\n",
    "### Sinle number evaluation metric\n",
    "\n",
    "- Precision: of examples recognized as cat, what % actually are cats?\n",
    "- Recall: what % of actual cats are correctly recognized.\n",
    "- F1 score: \"average\" of precision and recall.\n",
    "    - $\\dfrac{2}{\\dfrac{1}{P}+\\dfrac{1}{R}}$\n",
    "\n",
    "### Satisfying and optimizaing metric\n",
    "\n",
    "- Ex. maximize accuracy subject to running_time $\\le 100ms$\n",
    "- $N$ metrics: $1$ optimizing, $N-1$ satisfying.\n",
    "\n",
    "### Train/dev/test distributions\n",
    "\n",
    "- Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on.\n",
    "- Dev and test set must come from the same distribution.\n",
    "\n",
    "### Size of dev/test sets\n",
    "\n",
    "- Set your test set to be big enough to give high confidence in the overall performance of your system.\n",
    "\n",
    "### When to change dev/test sets and metrics\n",
    "\n",
    "- If doing well on your metric and dev/test set does not correcpond to doing well on your application, change your metric and/or dev/test set.\n",
    "\n",
    "## Comparing to human-level performance\n",
    "\n",
    "### Why human-level performance\n",
    "\n",
    "- While ML is worse than human, you can\n",
    "    - Get labeled data from human.\n",
    "    - Gain insight from manual error analysis. (why did a person get this right?)\n",
    "    - Better analysis of bias/variance.\n",
    "    \n",
    "### Avoidable bias\n",
    "\n",
    "- Human error as a proxy for bays error.\n",
    "- Gap between human and training error: avoidable bias.\n",
    "- Gap between training and dev error: variance.\n",
    "\n",
    "### Two fundamental assumptions of supervised learning\n",
    "\n",
    "- You can fit the training set pretty well ~ avoidable bias.\n",
    "- Training set performance generalizes pretty well to dev/test set ~ variance.\n",
    "- Avoidable bias\n",
    "    - Traing bigger model.\n",
    "    - Train longer / use better optimization algorithms.\n",
    "    - NN architecture / hyperparameters search.\n",
    "- Dev error\n",
    "    - More data.\n",
    "    - Regularization.\n",
    "    - NN architecture / hyperparameters search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "### Carrying out error analysis\n",
    "\n",
    "- Look at dev examples to evaluate ideas.\n",
    "- Ex. cat detection\n",
    "    - Dog being recognized as cats.\n",
    "    - Big cats (lions, panthers, etc) being recognized as cats.\n",
    "    - Blurry images.\n",
    "    \n",
    "### Cleaning up incorrectly labeled data\n",
    "\n",
    "- DL algorithms are quite robust to random errors (not systematic) errors in training set.\n",
    "- Consider errors due to incorrect labels vs. errors due to other causes.\n",
    "- Apply same process to your dev and test sets to make sure they continue to come from the same distributions.\n",
    "- Consider examining examples your algorithms got right as well as ones it got wrong.\n",
    "- Train and dev/test data may now come from slightly different distributions.\n",
    "\n",
    "#### Build your first system quickly, then iterate\n",
    "\n",
    "- Set up dev/test set and metric.\n",
    "- Build initial system quickly.\n",
    "- Use bias/variance analysis & error analysis to prioritize next steps.\n",
    "\n",
    "## Mismatched training and dev/test set\n",
    "\n",
    "### Training and testing on different distributions\n",
    "\n",
    "- Ex. cat (data from webpages (200,000) and mobile app (10,000))\n",
    "    - Train: 200,000 from web + 5,000 from mobile.\n",
    "    - Dev: 2,500 from mobile.\n",
    "    - Test: 2,500 from mobile.\n",
    "    - This is to ensure dev & test sets come from the same distribution.\n",
    "- Ex. speech recognition\n",
    "    - Training: purchased data, smart speaker control, voice keyboard.\n",
    "    - Dev/test: speech activated rearview mirror.\n",
    "    \n",
    "### Bias and variance with mismatched data distribution\n",
    "\n",
    "- Training-dev set: same distribution as training set, but not used for training.\n",
    "- Gap between human-level and training error? avoidable bias.\n",
    "- Gap between training and training-dev error? variance.\n",
    "- Gap between training-dev and dev error? data mismatch.\n",
    "- Gap between test and dev error? degree of overfitting to dev set.\n",
    "\n",
    "### Addressing data mismatch\n",
    "\n",
    "- Carry out manual error analysis to try to understand difference between training and dev/test sets.\n",
    "- Make training data more similar, or collect more data similar to dev/test sets.\n",
    "    - Artificial data synthesis.\n",
    "    \n",
    "## Learning from mutiple tasks\n",
    "\n",
    "### Transfer learning (from A to B)\n",
    "\n",
    "- Task A and B have the same input $x$\n",
    "- You have a lot more data for task A than task B.\n",
    "- Low level features from A could be helpful for learning B.\n",
    "\n",
    "### Multi-task learning\n",
    "\n",
    "- Training on a set of tasks that could benefit from having shared lower-level features.\n",
    "- Usually, amount of data you have for each task is quite similar.\n",
    "- Can train a big enough neural network to do well on all the tasks.\n",
    "\n",
    "## End-to-end deep learning\n",
    "\n",
    "Speech recognition example\n",
    "- Audio $\\rightarrow$ features $\\rightarrow$ phonemes $\\rightarrow$ workds $\\rightarrow$ trainscript Vs. audio $\\rightarrow$ trainscript.\n",
    "\n",
    "Machine translation example\n",
    "- English $\\rightarrow$ text analysis $\\rightarrow$ $\\dots$ $\\rightarrow$ french vs. english $\\rightarrow$ french.\n",
    "\n",
    "Pros\n",
    "- Let the data speak.\n",
    "- Less hand-designing of components needed.\n",
    "\n",
    "Cons\n",
    "- May need large amount of data.\n",
    "- Exclude potentially useful hand-designed components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
