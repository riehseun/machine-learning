{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring Machine Learning Projects\n",
    "\n",
    "## Introduction to ML strategy\n",
    "\n",
    "### Orthogonalization\n",
    "\n",
    "- fit training set well on cost function (bigger network, better optimization algorithm)\n",
    "- then, fit dev set well on cost function (regularization, bigger training set)\n",
    "- then, fit test set well on cost function (bigger dev set)\n",
    "- then, perform well in real world (change dev set or cost function)\n",
    "\n",
    "## Setting up your goal\n",
    "\n",
    "### Sinle number evaluation metric\n",
    "\n",
    "- precision: of examples recognized as cat, what % actually are cats?\n",
    "- recall: what % of actual cats are correctly recognized\n",
    "- F1 score: \"average\" of precision and recall\n",
    "    - $\\dfrac{2}{\\dfrac{1}{P}+\\dfrac{1}{R}}$\n",
    "\n",
    "### Satisfying and optimizaing metric\n",
    "\n",
    "- ex. maximize accuracy subject to running_time $\\le 100ms$\n",
    "- $N$ metrics: $1$ optimizing, $N-1$ satisfying\n",
    "\n",
    "### Train/dev/test distributions\n",
    "\n",
    "- choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on\n",
    "- dev and test set must come from the same distribution\n",
    "\n",
    "### Size of dev/test sets\n",
    "\n",
    "- set your test set to be big enough to give high confidence in the overall performance of your system\n",
    "\n",
    "### When to change dev/test sets and metrics\n",
    "\n",
    "- if doing well on your metric and dev/test set does not correcpond to doing well on your application, change your metric and/or dev/test set\n",
    "\n",
    "## Comparing to human-level performance\n",
    "\n",
    "### Why human-level performance\n",
    "\n",
    "- while ML is worse than human, you can\n",
    "    - get labeled data from human\n",
    "    - gain insight from manual error analysis (why did a person get this right?)\n",
    "    - better analysis of bias/variance\n",
    "    \n",
    "### Avoidable bias\n",
    "\n",
    "- human error as a proxy for bays error\n",
    "- gap between human and training error: avoidable bias\n",
    "- gap between training and dev error: variance\n",
    "\n",
    "### Two fundamental assumptions of supervised learning\n",
    "\n",
    "- you can fit the training set pretty well ~ avoidable bias\n",
    "- training set performance generalizes pretty well to dev/test set ~ variance\n",
    "- avoidable bias\n",
    "    - traing bigger model\n",
    "    - train longer / use better optimization algorithms\n",
    "    - NN architecture / hyperparameters search\n",
    "- dev error\n",
    "    - more data\n",
    "    - regularization\n",
    "    - NN architecture / hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "### Carrying out error analysis\n",
    "\n",
    "- look at dev examples to evaluate ideas\n",
    "- ex. cat detection\n",
    "    - dog being recognized as cats\n",
    "    - big cats (lions, panthers, etc) being recognized as cats\n",
    "    - blurry images\n",
    "    \n",
    "### Cleaning up incorrectly labeled data\n",
    "\n",
    "- DL algorithms are quite robust to random errors (not systematic) errors in training set\n",
    "- consider errors due to incorrect labels vs. errors due to other causes\n",
    "- apply same process to your dev and test sets to make sure they continue to come from the same distributions\n",
    "- consider examining examples your algorithms got right as well as ones it got wrong\n",
    "- train and dev/test data may now come from slightly different distributions\n",
    "\n",
    "#### Build your first system quickly, then iterate\n",
    "\n",
    "- set up dev/test set and metric\n",
    "- build initial system quickly\n",
    "- use bias/variance analysis & error analysis to prioritize next steps\n",
    "\n",
    "## Mismatched training and dev/test set\n",
    "\n",
    "### Training and testing on different distributions\n",
    "\n",
    "- ex. cat (data from webpages (200,000) and mobile app (10,000))\n",
    "    - train: 200,000 from web + 5,000 from mobile\n",
    "    - dev: 2,500 from mobile\n",
    "    - test: 2,500 from mobile\n",
    "    - this is to ensure dev & test sets come from the same distribution\n",
    "- ex. speech recognition\n",
    "    - training: purchased data, smart speaker control, voice keyboard\n",
    "    - dev/test: speech activated rearview mirror\n",
    "    \n",
    "### Bias and variance with mismatched data distribution\n",
    "\n",
    "- training-dev set: same distribution as training set, but not used for training\n",
    "- gap between human-level and training error? avoidable bias\n",
    "- gap between training and training-dev error? variance\n",
    "- gap between training-dev and dev error? data mismatch\n",
    "- gap between test and dev error? degree of overfitting to dev set\n",
    "\n",
    "### Addressing data mismatch\n",
    "\n",
    "- carry out manual error analysis to try to understand difference between training and dev/test sets\n",
    "- make training data more similar, or collect more data similar to dev/test sets\n",
    "    - artificial data synthesis\n",
    "    \n",
    "## Learning from mutiple tasks\n",
    "\n",
    "### Transfer learning (from A to B)\n",
    "\n",
    "- task A and B have the same input $x$\n",
    "- you have a lot more data for task A than task B\n",
    "- low level features from A could be helpful for learning B\n",
    "\n",
    "### Multi-task learning\n",
    "\n",
    "- training on a set of tasks that could benefit from having shared lower-level features\n",
    "- usually, amount of data you have for each task is quite similar\n",
    "- can train a big enough neural network to do well on all the tasks\n",
    "\n",
    "## End-to-end deep learning\n",
    "\n",
    "Speech recognition example\n",
    "- audio $\\rightarrow$ features $\\rightarrow$ phonemes $\\rightarrow$ workds $\\rightarrow$ trainscript vs. audio $\\rightarrow$ trainscript\n",
    "\n",
    "Machine translation example\n",
    "- english $\\rightarrow$ text analysis $\\rightarrow$ $\\dots$ $\\rightarrow$ french vs. english $\\rightarrow$ french\n",
    "\n",
    "Pros\n",
    "- let the data speak\n",
    "- less hand-designing of components needed\n",
    "\n",
    "Cons\n",
    "- may need large amount of data\n",
    "- exclude potentially useful hand-designed components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
