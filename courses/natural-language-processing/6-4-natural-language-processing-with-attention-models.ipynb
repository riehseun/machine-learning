{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Attention Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation\n",
    "\n",
    "### Attention\n",
    "- Uses both input (encoder hidden state) and output (decoder hidden state)\n",
    "- Keys and values are pairs, and they both have diemesion $N$. \n",
    "- $N$ comes from input and quries come from output.\n",
    "\n",
    "![4-1-1](images/natural-language-processing/4-1-1.png)\n",
    "\n",
    "- We can represent word embedding in English as key and value.\n",
    "- Quries then will be German equivalent.\n",
    "- Calculate dot product between query and key. (similar vertors have higher value and non-similar verctors have lower value)\n",
    "- Compute $softmax(QK^{T})V$\n",
    "\n",
    "### Teacher forcing\n",
    "- At each step making a prediction, peek into the right answer and feed it into the next time step.\n",
    "    \n",
    "![4-1-2](images/natural-language-processing/4-1-2.png)\n",
    "\n",
    "- Input is represented by $0$ and target is represented by 1.\n",
    "- Input token is fed into input coder, and is transformed to key and value vector.\n",
    "- Target token goes into pre-attention decoder, is transformed to query vector $Q$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1 Stack semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np              # regular ol' numpy\n",
    "from trax import layers as tl   # core building block\n",
    "from trax import shapes         # data signatures: dimensionality and type\n",
    "from trax import fastmath       # uses jax, offers numpy on steroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Addition():\n",
    "    layer_name = \"Addition\"  # don't forget to give your custom layer a name to identify\n",
    "\n",
    "    # Custom function for the custom layer\n",
    "    def func(x, y):\n",
    "        return x + y\n",
    "\n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "\n",
    "# Test it\n",
    "add = Addition()\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", add.name)\n",
    "print(\"expected inputs :\", add.n_in)\n",
    "print(\"promised outputs :\", add.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x = np.array([3])\n",
    "y = np.array([4])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "print(\"y :\", y, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "z = add((x, y))\n",
    "print(\"-- Outputs --\")\n",
    "print(\"z :\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multiplication():\n",
    "    layer_name = (\n",
    "        \"Multiplication\"  # don't forget to give your custom layer a name to identify\n",
    "    )\n",
    "\n",
    "    # Custom function for the custom layer\n",
    "    def func(x, y):\n",
    "        return x * y\n",
    "\n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "\n",
    "# Test it\n",
    "mul = Multiplication()\n",
    "\n",
    "# Inspect properties\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", mul.name)\n",
    "print(\"expected inputs :\", mul.n_in)\n",
    "print(\"promised outputs :\", mul.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "x = np.array([7])\n",
    "y = np.array([15])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "print(\"y :\", y, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "z = mul((x, y))\n",
    "print(\"-- Outputs --\")\n",
    "print(\"z :\", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial combinator\n",
    "serial = tl.Serial(\n",
    "    Addition(), Multiplication(), Addition()  # add 3 + 4  # multiply result by 15\n",
    ")\n",
    "\n",
    "# Initialization\n",
    "x = (np.array([3]), np.array([4]), np.array([15]), np.array([3]))  # input\n",
    "\n",
    "serial.init(shapes.signature(x))  # initializing serial instance\n",
    "\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial, \"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"sublayers :\", serial.sublayers)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial = tl.Serial(tl.Select([0, 1, 0, 1]), Addition(), Multiplication(), Addition())\n",
    "\n",
    "# Initialization\n",
    "x = (np.array([3]), np.array([4]))  # input\n",
    "\n",
    "serial.init(shapes.signature(x))  # initializing serial instance\n",
    "\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial, \"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"sublayers :\", serial.sublayers)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial = tl.Serial(\n",
    "    tl.Select([0, 1, 0, 1]), Addition(), tl.Select([0], n_in=2), Multiplication()\n",
    ")\n",
    "\n",
    "# Initialization\n",
    "x = (np.array([3]), np.array([4]))  # input\n",
    "\n",
    "serial.init(shapes.signature(x))  # initializing serial instance\n",
    "\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial, \"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"sublayers :\", serial.sublayers)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out, \"\\n\")\n",
    "\n",
    "# Inputs\n",
    "print(\"-- Inputs --\")\n",
    "print(\"x :\", x, \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial(x)\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a Serial network\n",
    "serial = tl.Serial(\n",
    "    # Practice using Select again by duplicating the first two inputs\n",
    "    tl.Select([0, 1, 0, 1]),\n",
    "    # Place a Residual layer that skips over the Fn: Addition() layer\n",
    "    tl.Residual(Addition())\n",
    ")\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial, \"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "x1 = np.array([3])\n",
    "x2 = np.array([4])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"(x1, x2) :\", (x1, x2), \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial((x1, x2))\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "serial = tl.Serial(\n",
    "    tl.Select([0, 1, 0, 1]), \n",
    "    tl.Residual(Multiplication())\n",
    ")\n",
    "\n",
    "print(\"-- Serial Model --\")\n",
    "print(serial, \"\\n\")\n",
    "print(\"-- Properties --\")\n",
    "print(\"name :\", serial.name)\n",
    "print(\"expected inputs :\", serial.n_in)\n",
    "print(\"promised outputs :\", serial.n_out, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "x1 = np.array([3])\n",
    "x2 = np.array([4])\n",
    "print(\"-- Inputs --\")\n",
    "print(\"(x1, x2) :\", (x1, x2), \"\\n\")\n",
    "\n",
    "# Outputs\n",
    "y = serial((x1, x2))\n",
    "print(\"-- Outputs --\")\n",
    "print(\"y :\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2 BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # import numpy to make numerical computations.\n",
    "import nltk                         # import NLTK to handle simple NL tasks like tokenization.\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')\n",
    "import math\n",
    "from collections import Counter     # import the Counter module.\n",
    "!pip3 install 'sacrebleu'           # install the sacrebleu package.\n",
    "import sacrebleu                    # import sacrebleu in order compute the BLEU score.\n",
    "import matplotlib.pyplot as plt     # import pyplot in order to make some illustrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_length = np.ones(100)\n",
    "can_length = np.linspace(1.5, 0.5, 100)\n",
    "x = ref_length / can_length\n",
    "y = 1 - x\n",
    "y = np.exp(y)\n",
    "y = np.minimum(np.ones(y.shape), y)\n",
    "\n",
    "# Code for in order to make the plot\n",
    "fig, ax = plt.subplots(1)\n",
    "lines = ax.plot(x, y)\n",
    "ax.set(\n",
    "    xlabel=\"Ratio of the length of the reference to the candidate text\",\n",
    "    ylabel=\"Brevity Penalty\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"1-gram\": 0.8, \"2-gram\": 0.7, \"3-gram\": 0.6, \"4-gram\": 0.5}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "bars = ax.bar(names, values)\n",
    "ax.set(ylabel=\"N-gram precision\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"1-gram\": 0.8, \"2-gram\": 0.77, \"3-gram\": 0.74, \"4-gram\": 0.71}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "bars = ax.bar(names, values)\n",
    "ax.set(ylabel=\"Modified N-gram precision\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"The NASA Opportunity rover is battling a massive dust storm on planet Mars.\"\n",
    "candidate_1 = \"The Opportunity rover is combating a big sandstorm on planet Mars.\"\n",
    "candidate_2 = \"A NASA rover is fighting a massive storm on planet Mars.\"\n",
    "\n",
    "tokenized_ref = nltk.word_tokenize(reference.lower())\n",
    "tokenized_cand_1 = nltk.word_tokenize(candidate_1.lower())\n",
    "tokenized_cand_2 = nltk.word_tokenize(candidate_2.lower())\n",
    "\n",
    "print(f\"{reference} -> {tokenized_ref}\")\n",
    "print(\"\\n\")\n",
    "print(f\"{candidate_1} -> {tokenized_cand_1}\")\n",
    "print(\"\\n\")\n",
    "print(f\"{candidate_2} -> {tokenized_cand_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate, reference):\n",
    "    ref_length = len(reference)\n",
    "    can_length = len(candidate)\n",
    "\n",
    "    # Brevity Penalty\n",
    "    if ref_length < can_length: # if reference length is less than candidate length\n",
    "        BP = 1 # set BP = 1\n",
    "    else:\n",
    "        penalty = 1 - (ref_length / can_length) # else set BP=exp(1-(ref_length/can_length))\n",
    "        BP = np.exp(penalty)\n",
    "\n",
    "    return BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_precision(candidate, reference):\n",
    "    \"\"\"\n",
    "    Clipped precision function given a original and a machine translated sentences\n",
    "    \"\"\"\n",
    "\n",
    "    clipped_precision_score = []\n",
    "    \n",
    "    for i in range(1, 5):\n",
    "        ref_n_gram = Counter(ngrams(reference,i))\n",
    "        cand_n_gram = Counter(ngrams(candidate,i))\n",
    "\n",
    "        c = sum(cand_n_gram.values())\n",
    "        \n",
    "        for j in cand_n_gram: # for every n-gram up to 4 in candidate text\n",
    "            if j in ref_n_gram: # check if it is in the reference n-gram\n",
    "                if cand_n_gram[j] > ref_n_gram[j]: # if the count of the candidate n-gram is bigger\n",
    "                                                   # than the corresponding count in the reference n-gram,\n",
    "                    cand_n_gram[j] = ref_n_gram[j] # then set the count of the candidate n-gram to be equal\n",
    "                                                   # to the reference n-gram\n",
    "            else:\n",
    "                cand_n_gram[j] = 0 # else set the candidate n-gram equal to zero\n",
    "\n",
    "        clipped_precision_score.append(sum(cand_n_gram.values())/c)\n",
    "\n",
    "    weights =[0.25]*4\n",
    "\n",
    "    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "    s = math.exp(math.fsum(s))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(candidate, reference):\n",
    "    BP = brevity_penalty(candidate, reference)\n",
    "    precision = clipped_precision(candidate, reference)\n",
    "    return BP * precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 our own code BLEU: \",\n",
    "    round(bleu_score(tokenized_cand_1, tokenized_ref) * 100, 1),\n",
    ")\n",
    "print(\n",
    "    \"Results reference versus candidate 2 our own code BLEU: \",\n",
    "    round(bleu_score(tokenized_cand_2, tokenized_ref) * 100, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 sacrebleu library BLEU: \",\n",
    "    round(sacrebleu.corpus_bleu(candidate_1, reference).score, 1),\n",
    ")\n",
    "print(\n",
    "    \"Results reference versus candidate 2 sacrebleu library BLEU: \",\n",
    "    round(sacrebleu.corpus_bleu(candidate_2, reference).score, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the raw data\n",
    "wmt19_src = open(\"wmt19_src.txt\", \"rU\")\n",
    "wmt19_src_1 = wmt19_src.read()\n",
    "wmt19_src.close()\n",
    "wmt19_ref = open(\"wmt19_ref.txt\", \"rU\")\n",
    "wmt19_ref_1 = wmt19_ref.read()\n",
    "wmt19_ref.close()\n",
    "wmt19_can = open(\"wmt19_can.txt\", \"rU\")\n",
    "wmt19_can_1 = wmt19_can.read()\n",
    "wmt19_can.close()\n",
    "\n",
    "tokenized_corpus_src = nltk.word_tokenize(wmt19_src_1.lower())\n",
    "tokenized_corpus_ref = nltk.word_tokenize(wmt19_ref_1.lower())\n",
    "tokenized_corpus_cand = nltk.word_tokenize(wmt19_can_1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"English source text:\")\n",
    "print(\"\\n\")\n",
    "print(f\"{wmt19_src_1[0:170]} -> {tokenized_corpus_src[0:30]}\")\n",
    "print(\"\\n\")\n",
    "print(\"German reference translation:\")\n",
    "print(\"\\n\")\n",
    "print(f\"{wmt19_ref_1[0:219]} -> {tokenized_corpus_ref[0:35]}\")\n",
    "print(\"\\n\")\n",
    "print(\"German machine translation:\")\n",
    "print(\"\\n\")\n",
    "print(f\"{wmt19_can_1[0:199]} -> {tokenized_corpus_cand[0:29]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 our own BLEU implementation: \",\n",
    "    round(bleu_score(tokenized_corpus_cand, tokenized_corpus_ref) * 100, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Results reference versus candidate 1 sacrebleu library BLEU: \",\n",
    "    round(sacrebleu.corpus_bleu(wmt19_can_1, wmt19_ref_1).score, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
