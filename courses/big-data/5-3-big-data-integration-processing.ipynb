{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big data integration and processing\n",
    "\n",
    "Data modelling\n",
    "- tells how data is structured and what operations can be done\n",
    "- relational, semi-structured, graph, text\n",
    "\n",
    "BDMS\n",
    "- designed for parallel and distributed processing \n",
    "- may not guarantee consistency (most likely supports eventual consistency)\n",
    "- often built on Hadoop\n",
    "\n",
    "Requirement of BDMS\n",
    "- support big data operations (split volumns of data, access data fast, distribute computations to nodes)\n",
    "- handle fault tolerance (replicate data partitions, recover files when needed)\n",
    "- enable scaling out\n",
    "- optimized and extensible for many data types\n",
    "- enable both streaming and batch processing (low latency and accuracy)\n",
    "\n",
    "Query Langugage\n",
    "- declaritive: specify what you need rather than how to obtain it\n",
    "\n",
    "When data is stored in multiple machines\n",
    "- local indexing: use local index on each machine\n",
    "- global indexing: use a combined index in a global index server\n",
    "\n",
    "Semijoin (used in distributed settings)\n",
    "- A semijoin from R to S reduce data transmission cost\n",
    "- steps\n",
    "    - \"Project\" R on attribute A (call it R[A])\n",
    "    - \"Step\" this projection from the site of R to the site of S\n",
    "    - \"Reduce\" S by eliminating tuples where attribute A are not matching any value in R[A]\n",
    "\n",
    "Querying MongoDB\n",
    "- EX1\n",
    "    - SQL: SELECT * FROM Beers\n",
    "    - MongoDB: db.Beers.find()\n",
    "- EX2\n",
    "    - SQL: SELECT beer, price FROM Sells\n",
    "    - MongoDB: db.Sells.find({}, {beer:1, price:1})\n",
    "- EX3\n",
    "    - SQL: SELECT manf FROM Beers WHERE name = \"Heineken\"\n",
    "    - MongoDB: db.Beers.find({name: \"Heineken\"}, {manf:1, _id:0})\n",
    "- EX4\n",
    "    - SQL: SELECT DISTINCT beer, price FROM Sells WHERE price > 15\n",
    "    - MongoDB: db.Sells.distinct({price:{\\$gt>15}}, {beer:1, price:1, _id:0})    \n",
    "- EX5: \n",
    "    - count the number of manufacturers whose names have the partial string \"am\" in it (case insensitive) \n",
    "    - MongoDB: db.Beers.find(name: {\\$regex:/^am/i}).count()\n",
    "- EX6: \n",
    "    - count the number of manufacturers whose names starts with \"am\" and ends with corp\"\" \n",
    "    - MongoDB: db.Beers.find(name: {\\$regex:/^am.*corp\\$/}).count()\n",
    "- EX7: \n",
    "    - find items which are tagged as \"popular\" or \"organic\"\n",
    "    - MongoDB: db.inventory.find({tags: {\\$in: [\"popular\", \"organic\"]}})\n",
    "- EX8: \n",
    "    - find items which are not tagged as \"popular\" or \"organic\"\n",
    "    - MongoDB: db.inventory.find({tags: {\\$nin: [\"popular\", \"organic\"]}})\n",
    "- EX9: \n",
    "    - find 2nd and 3rd element of tags\n",
    "    - MongoDB: db.inventory.find({}, {tags: {\\$slice: [1,2]}})\n",
    "- EX10: \n",
    "    - find a document whose 2nd element in tags is \"summer\"\n",
    "    - MongoDB: db.inventory.find(tags.1: \"summer\")\n",
    "- EX11: \n",
    "    - count the number of unique addresses of drinkers\n",
    "    - MongoDB: db.Drinkers.count(addr: {\\$exist: true})\n",
    "- EX12: \n",
    "    - get the distinct values of array\n",
    "    - MongoDB: db.countryDB.distinct(places)\n",
    "- EX13:\n",
    "    - How many tweets have location not null?\n",
    "    - db.users.find({\"user.Location\": null}).count()\n",
    "- EX14:\n",
    "    - How many people have more followers than friends?\n",
    "    - db.users.find({ \\$where : \"this.user.FollowersCount > this.user.FriendsCount\"}).count()\n",
    "- EX15:\n",
    "    - Perform a query that returns the text of tweets which have the string \"http://\"\n",
    "    - db.users.find({\"tweet_text\" : {\\$regex : \".*http://.*\"}})\n",
    "- EX16:\n",
    "    - Get all the tweets from the location \"Ireland\" which also contain the string \"UEFA\"\n",
    "    - db.users.find({\"tweet_text\" : {\\$regex : \"UEFA\"}, \"user.Location\" : \"Ireland\"})\n",
    "    \n",
    "## Data information integration\n",
    "\n",
    "- problem: too many soources\n",
    "- solution: \n",
    "    - pay-as-you-go model: only integrate sources that are needed when needed\n",
    "    - probablistic schema mapping\n",
    "        - mediated schema\n",
    "           - attribute grouping\n",
    "               - similarity of attribute\n",
    "               - probability of two attribute co-occuring\n",
    "               \n",
    "Data fusion\n",
    "- data item: particular aspect of real-world entity\n",
    "- find true values of data items from sources\n",
    "\n",
    "Too many data sources\n",
    "- many values for the same item => leads to conflicts\n",
    "- hard to estimate trustworthiness of sources\n",
    "\n",
    "## Big data processing pipeline\n",
    "\n",
    "Map reduce\n",
    "- split -> map -> shuffle and sort -> reduce\n",
    "\n",
    "Data parallelism\n",
    "- running the same function simultaneously for partition of data set on multiple cores\n",
    "\n",
    "Three layers of Hadoop\n",
    "- data management and storage\n",
    "- data integration and processing\n",
    "- coordination and workflow management\n",
    "\n",
    "Categorization of big data processing systems\n",
    "- execution model: batch (Hadoop, Spark, Flink, beam), streaming (Spark, Flink, beam, Storm) \n",
    "- latency: high-latency (Hadoop: no in-memory processing), low-latency (Spark, Flink, beam: in-memory processing), very low-latency (Storm)\n",
    "- scailability: \n",
    "- programming model: Java (Hadoop, Flink, beam), Scala (Spark, Flink, beam), Python (Spark), R (Spark)\n",
    "- fault tolerence: replication (Hadoop)\n",
    "\n",
    "Lambda architecture\n",
    "- hybrid data processing architecture\n",
    "\n",
    "Hadoop limitation\n",
    "- only map-reduce based computation\n",
    "- no interactive shell \n",
    "- native support for Java only\n",
    "- relies on reading data from HDFS, which become a bottleneck\n",
    "\n",
    "Spark\n",
    "- resilent distributed datasets (RDD)\n",
    "- driver program creates RDD\n",
    "- create RDD -> apply transformation -> lazily evaluated and action performed\n",
    "    - transformations will wait until actions are performed\n",
    "    - errors may show up in action stage, not in transformation stage \n",
    "\n",
    "Narrow transformations \n",
    "- take place in worker nodes locally\n",
    "- map: apply function to each element of RDD\n",
    "- flatMap: map then flatten output\n",
    "- filter: keep only elements where function is true\n",
    "- coalesce: reduce number of partitions\n",
    "\n",
    "Wide transformations\n",
    "- processing depends on data residing in multiple partitions distributed across worker nodes\n",
    "- groupByKey: (K, V) pairs => (K, list of all V)\n",
    "\n",
    "Actions\n",
    "- collect: copy all elements to the driver\n",
    "- take(n): copy first n elements\n",
    "- reduce(func): aggregate elements with func\n",
    "- saveAsTextFile(filename): save to local file or HDFS\n",
    "\n",
    "Spark SQL\n",
    "- enables querying structured and unstructured data through Spark\n",
    "- APIs for Scala, Java, Python to convert result into RDDs\n",
    "- deploy business intelligence tools over Spark\n",
    "\n",
    "Data frames\n",
    "- looks just like tables in relational databases\n",
    "- RDDs can be converted to data frames \n",
    "\n",
    "Spark streaming\n",
    "- sources: Kafka, Flume, HDFS, S3, etc\n",
    "\n",
    "Spark MLLib\n",
    "- machine learning library for Spark\n",
    "\n",
    "Spark GraphX\n",
    "- API for graph computation\n",
    "- triplets: views that logically join vertex and edge properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
