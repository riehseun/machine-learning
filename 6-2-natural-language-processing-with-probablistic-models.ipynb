{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrect\n",
    "\n",
    "- Identify a mis-spelled word\n",
    "- Find string $n$ edit distances away\n",
    "- Filter candidates (by keeping only real words from the previous step)\n",
    "- Calculate word probabilities by taking the context into consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in your current directory. You just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    all_words = [] # return this variable correctly\n",
    "\n",
    "    content = open(file_name, \"r\").read()\n",
    "    content = content.lower()\n",
    "    all_words = re.findall(r'\\w+', content)\n",
    "    \n",
    "    return all_words\n",
    "\n",
    "\n",
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    \n",
    "    word_count_dict = {}  # fill this with word counts\n",
    "\n",
    "    for word in word_l:\n",
    "        if word not in word_count_dict:\n",
    "            word_count_dict[word] = 1\n",
    "        else:\n",
    "            word_count_dict[word] += 1\n",
    "    \n",
    "    return word_count_dict\n",
    "\n",
    "\n",
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}  # return this variable correctly\n",
    "    \n",
    "    total = 0 \n",
    "    for word in word_count_dict:\n",
    "        total += word_count_dict[word]\n",
    "        \n",
    "    for word in word_count_dict:\n",
    "        probs[word] = word_count_dict[word] / total\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    # 'nice' is split into : [('', 'nice'), ('n', 'ice'), ('ni', 'ce'), ('nic', 'e'), ('nice', '')]\n",
    "    # For our 'nice' example you get: ['ice', 'nce', 'nie', 'nic']\n",
    "    for i in range(len(word)):\n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        \n",
    "    for j in range(len(split_l)):\n",
    "        first = split_l[j][0]\n",
    "        second = split_l[j][1]\n",
    "        new = first + second\n",
    "        delete_l.append(new[:j]+new[j+1:])\n",
    "    \n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return delete_l\n",
    "\n",
    "\n",
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    if len(word) == 1:\n",
    "        return word\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        \n",
    "    for (a,b) in split_l:\n",
    "        if len(a) > 1 and len(b) > 1:\n",
    "            temp1 = b[0]\n",
    "            temp2 = a[len(a)-1]\n",
    "            switch_l.append(a[len(a)-2]+temp1+temp2+b[1:])\n",
    "        elif len(a) == 1 and len(b) > 1:\n",
    "            temp1 = b[0]\n",
    "            temp2 = a[len(a)-1]\n",
    "            switch_l.append(temp1+temp2+b[1:])\n",
    "        elif len(a) > 1 and len(b) == 1:\n",
    "            temp1 = b[0]\n",
    "            temp2 = a[len(a)-1]\n",
    "            switch_l.append(a[len(a)-2]+temp1+temp2)\n",
    "        elif len(a) == 1 and len(b) == 1:\n",
    "            switch_l.append(b+a)\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "\n",
    "    return switch_l\n",
    "\n",
    "\n",
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        \n",
    "    # TODO\n",
    "                \n",
    "    if word in replace_l:\n",
    "        replace_l.remove(word)\n",
    "        \n",
    "    replace_set = set(replace_l)\n",
    "    \n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l\n",
    "\n",
    "\n",
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)+1):\n",
    "        split_l.append((word[:i], word[i:]))\n",
    "            \n",
    "    for j in range(len(word)+1):\n",
    "        for k in letters:\n",
    "            if j == 0:\n",
    "                insert_l.append(k+word)\n",
    "            elif j == len(word):\n",
    "                insert_l.append(word+k)\n",
    "            else:\n",
    "                insert_l.append(word[:j]+k+word[j:])\n",
    "\n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l\n",
    "\n",
    "\n",
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    inserts = insert_letter(word)\n",
    "    for i in inserts:\n",
    "        edit_one_set.add(i)\n",
    "        \n",
    "    deletes = delete_letter(word)\n",
    "    for j in deletes:\n",
    "        edit_one_set.add(j)\n",
    "        \n",
    "    replaces = replace_letter(word)\n",
    "    for k in replaces:\n",
    "        edit_one_set.add(k)\n",
    "            \n",
    "    if allow_switches:\n",
    "        switches = switch_letter(word)\n",
    "        for k in switches:\n",
    "            edit_one_set.add(k)\n",
    "            \n",
    "    if word in edit_one_set:\n",
    "        edit_one_set.remove(word)\n",
    "\n",
    "    return edit_one_set\n",
    "\n",
    "\n",
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    edit_one_set = edit_one_letter(word)\n",
    "    for word_one_edit_away in edit_one_set:\n",
    "        word_two_edits_away = edit_one_letter(word_one_edit_away)\n",
    "        for w in word_two_edits_away:\n",
    "            edit_two_set.add(w)\n",
    "            \n",
    "    return edit_two_set.union(edit_one_set)\n",
    "\n",
    "\n",
    "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    if word in vocab:\n",
    "        n_best.append((word, probs[word]))\n",
    "        \n",
    "    edit_one_set = edit_one_letter(word, True)    \n",
    "    for word in edit_one_set:\n",
    "        if word in vocab:\n",
    "            n_best.append((word, probs[word]))\n",
    "    \n",
    "    edit_two_set = edit_two_letters(word, True)\n",
    "    for word in edit_two_set:\n",
    "        if word in vocab:\n",
    "            n_best.append((word, probs[word]))\n",
    "    \n",
    "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "\n",
    "    return n_best\n",
    "\n",
    "\n",
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    # use deletion and insert cost as  1\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "        \n",
    "    # Fill in column 0, from row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): # Replace None with the proper range\n",
    "        D[row,0] = D[row-1,0]+del_cost\n",
    "        \n",
    "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
    "    for col in range(1,n+1): # Replace None with the proper range\n",
    "        D[0,col] = D[0,col-1]+ins_cost\n",
    "        \n",
    "    # Loop through row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): \n",
    "        \n",
    "        # Loop through column 1 to column n, both inclusive\n",
    "        for col in range(1,n+1):\n",
    "            \n",
    "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # Check to see if source character at the previous row\n",
    "            # matches the target character at the previous column, \n",
    "            if source[row-1] == target[col-1]:\n",
    "                # Update the replacement cost to 0 if source and target are the same\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Update the cost at row, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
    "            D[row,col] = min(D[row-1,col]+del_cost, D[row,col-1]+ins_cost, D[row-1,col-1]+r_cost)\n",
    "          \n",
    "    # Set the minimum edit distance with the cost found at row m, column n\n",
    "    med = D[row,col]\n",
    "    \n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov chains\n",
    "\n",
    "![2-2-1](images/natural-language-processing/2-2-1.png)\n",
    "\n",
    "- $Q = \\{q_{1}, q_{2}, q_{3}\\}$: set of all states in the model\n",
    "\n",
    "![2-2-2](images/natural-language-processing/2-2-2.png)\n",
    "\n",
    "- Blue circles: part of speech tags\n",
    "- Arrows: transition probability from one part of speech to another\n",
    "- Table $A$ can be contructed from the diagram\n",
    "\n",
    "![2-2-3](images/natural-language-processing/2-2-3.png)\n",
    "\n",
    "- $A$ can also be written as transition matrix\n",
    "\n",
    "![2-2-4](images/natural-language-processing/2-2-4.png)\n",
    "\n",
    "- Emission probability: probability to go from one state (POS tag) to a specific word\n",
    "\n",
    "![2-2-5](images/natural-language-processing/2-2-5.png)\n",
    "\n",
    "- To populate emission matrix $B$, use labeled dataset\n",
    "\n",
    "![2-2-6](images/natural-language-processing/2-2-6.png)\n",
    "\n",
    "- $C(t_{(i−1)},t_{(i)})$ is the number of times that tag $t_{(i)}$ shows up after tag $t_{(i-1)}$\n",
    "\n",
    "![2-2-7](images/natural-language-processing/2-2-7.png)\n",
    "\n",
    "- $\\pi$ is the initial state\n",
    "- Numbers in the table indicates the number of times that a tag shows up right after another tag\n",
    "    - For example, Noun shows up after the initial state once, so 1\n",
    "    - For example, Other shows up after the inital state twice, so 2\n",
    "    \n",
    "![2-2-8](images/natural-language-processing/2-2-8.png)\n",
    "\n",
    "- To deal with \"no occurance\" problem, we introduce smoothing probability such that\n",
    "\n",
    "![2-2-9](images/natural-language-processing/2-2-9.png)\n",
    "\n",
    "![2-2-10](images/natural-language-processing/2-2-10.png)\n",
    "\n",
    "- We also use smoothing probability when populating Emission matrix\n",
    "- $P(W_{i}|t_{i}) = \\dfrac{C(t_{i},w_{i})+\\epsilon}{\\displaystyle\\sum_{j=1}^{V}C(t_{i},w_{i}) + N * \\epsilon} = = \\dfrac{C(t_{i},w_{i})+\\epsilon}{C(t_{i}) + N * \\epsilon}$\n",
    "    - where $C(t_{i},w_{i})$ means how many times tag $t_{i}$ is associated with word $w_{i}$ \n",
    "    \n",
    "    \n",
    "### Viterbi algorithm\n",
    "\n",
    "![2-2-11](images/natural-language-processing/2-2-11.png)\n",
    "\n",
    "- To go from $\\pi$ to $O$, multiply transition probability of 0.3 to emission probability of 0.5, which results in 0.15\n",
    "\n",
    "![2-2-12](images/natural-language-processing/2-2-12.png)\n",
    "\n",
    "### Viterbi initialization\n",
    "\n",
    "- Populate two matrices $C$ and $D$ such that\n",
    "\n",
    "![2-2-13](images/natural-language-processing/2-2-13.png)\n",
    "\n",
    "![2-2-14](images/natural-language-processing/2-2-14.png)\n",
    "\n",
    "\n",
    "### Viterbi forward pass\n",
    "\n",
    "![2-2-15](images/natural-language-processing/2-2-15.png)\n",
    "\n",
    "![2-2-16](images/natural-language-processing/2-2-16.png)\n",
    "\n",
    "\n",
    "### Viterbi backward pass\n",
    "\n",
    "![2-2-17](images/natural-language-processing/2-2-17.png)\n",
    "\n",
    "- This equation gets the top right element of matrix $C$\n",
    "\n",
    "![2-2-18](images/natural-language-processing/2-2-18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
