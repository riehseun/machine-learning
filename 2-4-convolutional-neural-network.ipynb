{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "\n",
    "- ex. 6x6 image * (convolve) 3x3 filter = 4x4 image\n",
    "- vertical edge detection: use filters such as\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {1} & 0 & {1}\\\\\n",
    "  0  & 1 & 0 \\\\\n",
    "  {1} & 0 & {1}\n",
    "\\end{array}\\right)$\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {1} & 0 & {-1}\\\\\n",
    "  2  & 0 & -2 \\\\\n",
    "  {1} & 0 & {-1}\n",
    "\\end{array}\\right)$ (Sobel filter)\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {3} & 0 & {-3}\\\\\n",
    "  10  & 0 & -10 \\\\\n",
    "  {3} & 0 & {-3}\n",
    "\\end{array}\\right)$ (Schors filter)\n",
    "\n",
    "- vertical edge detection: use filters such as\n",
    "\n",
    "$\\left(\\begin{array}{ccc}\n",
    "  {1} & 1 & {1}\\\\\n",
    "  0  & 0 & 0 \\\\\n",
    "  {-1} & -1 & {-1}\n",
    "\\end{array}\\right)$\n",
    "\n",
    "- $n$ x $n * f$ x $f = (n-f+1)$ x $(n-f+1)$\n",
    "\n",
    "## Padding\n",
    "\n",
    "- avoids shrinking output and throwing away information from edges\n",
    "- $n$ x $n * f$ x $f = (n+2p-f+1)$ x $(n+2p-f+1)$\n",
    "- \"valid\": no padding\n",
    "- \"same\": pad so that output size is the same as the input size\n",
    "    - $p = \\dfrac{f-1}{2}$ ($f$ is usually odd)\n",
    "\n",
    "## Strided convolutions\n",
    "\n",
    "- $n$ x $n * f$ x $f = (\\dfrac{n+2p-f}{2}+1)$ x $(\\dfrac{n+2p-f}{2}+1)$\n",
    "\n",
    "## Convolution over volumn\n",
    "\n",
    "- 6x6x3 volumn (height x width x number of channels) * 3x3x3 volume (height x width x number of channels) = 4x4 (27 numbers are multiplied and summed up 16 times to produce 4x4)\n",
    "- number of channel must match between input and filter\n",
    "- multuple filters\n",
    "    - 6x6x3 * 3x3x3 (two of these: one for vertical edge and the other for horizontal edge) = 4x4x2\n",
    "    - $n$ x $n$ x $n_{c} * f$ x $f$ x $n_{c} = (n-f+1)$ x $(n-f+1)$ x $n_{c}^{'}$ where $n_{c}^{'}$ = number of filters\n",
    "    \n",
    "## One layer of a convolutional network\n",
    "\n",
    "- if layer $l$ is a convolutional layer\n",
    "    - $f^{l}$ = filter size\n",
    "    - $p^{l}$ = padding\n",
    "    - $s^{l}$ = stride\n",
    "    - $n_{c}^{l}$ = number of filters\n",
    "    - input: $n_{H}^{[l-1]}$ x $n_{W}^{[l-1]}$ x $n_{c}^{[l-1]}$\n",
    "    - output: $n_{H}^{[l]}$ x $n_{W}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - $n^{[l]} = \\lfloor\\dfrac{n^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}} + 1\\rfloor$\n",
    "    - each filter: $f^{[l]}$ x $f^{[l]}$ x $n_{c}^{[l-1]}$\n",
    "    - activation: $a^{[l]}$ => $n_{H}^{[l]}$ x $n_{W}^{[l]}$ x $n_{c}^{[l]}$ or $A^{[l]}$ => $m$ x $n_{H}^{[l]}$ x $n_{W}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - weights: $f^{[l]}$ x $f^{[l]}$ x $n_{c}^{[l-1]}$ x $n_{c}^{[l]}$\n",
    "    - bias: $n_{c}^{[l]}$ (represented as $(1,1,1,n_{c}^{[l]})$)\n",
    "    \n",
    "## Pooling layers\n",
    "\n",
    "- max pooling: take max number in each region\n",
    "- $f$: filter size\n",
    "- $s$: stride\n",
    "- no parameters to learn\n",
    "\n",
    "## LeNet-5\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Activation shape</th>\n",
    "        <th>Activation size</th>\n",
    "        <th>Number of parameters</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Input</th>\n",
    "        <td>(32,32,3)</td>\n",
    "        <td>3072</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV1(f=5,s=1)</th>\n",
    "        <td>(28,28,6)</td>\n",
    "        <td>4704</td>\n",
    "        <td>608</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL1(f=2,s=2)</th>\n",
    "        <td>(14,14,6)</td>\n",
    "        <td>1176</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV2(f=5,s=1)</th>\n",
    "        <td>(10,10,6)</td>\n",
    "        <td>1600</td>\n",
    "        <td>3216</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL2(f=2,s=2)</th>\n",
    "        <td>(5,5,16)</td>\n",
    "        <td>400</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>FC3</th>\n",
    "        <td>(120,1)</td>\n",
    "        <td>120</td>\n",
    "        <td>48120</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>FC4</th>\n",
    "        <td>(84,1)</td>\n",
    "        <td>84</td>\n",
    "        <td>10164</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Softmax</th>\n",
    "        <td>(10,1)</td>\n",
    "        <td>10</td>\n",
    "        <td>850</td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "- about 60K parameters\n",
    "- width and height go down but number of channels goes up\n",
    "\n",
    "## Why convolutions\n",
    "\n",
    "- parameter sharing: a feature detector (such as vertical edge detector) that is useful in one part of the image is probably useful in another part of the image\n",
    "- sparsity of connections: in each layer, each output value depends only on a small number of inputs\n",
    "\n",
    "## AlexNet\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Activation shape</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Input</th>\n",
    "        <td>(227,227,3)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV(f=11,s=4)</th>\n",
    "        <td>(55,55,96)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL(f=3,s=2)</th>\n",
    "        <td>(27,27,96)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV(f=5,same)</th>\n",
    "        <td>(27,27,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL(f=3,s=2)</th>\n",
    "        <td>(13,13,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV(f=3,same)</th>\n",
    "        <td>(13,13,384)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV(f=3,same)</th>\n",
    "        <td>(13,13,384)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV(f=3,same)</th>\n",
    "        <td>(13,13,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL(f=3,s=2)</th>\n",
    "        <td>(6,6,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>FC</th>\n",
    "        <td>(4096,1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>FC</th>\n",
    "        <td>(4096,1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Softmax</th>\n",
    "        <td>(1000,1)</td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "- about 60M parameters\n",
    "- RELU\n",
    "\n",
    "## VGG-16\n",
    "\n",
    "- all CONVs are f=3,s=1,same\n",
    "- all POOLs are f=2,s=2\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Activation shape</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Input</th>\n",
    "        <td>(224,224,3)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(224,224,64)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(224,224,64)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL</th>\n",
    "        <td>(112,112,64)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL</th>\n",
    "        <td>(112,112,64)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(112,112,128)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(112,112,128)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>POOL</th>\n",
    "        <td>(56,56,128)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(56,56,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(56,56,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CONV</th>\n",
    "        <td>(56,56,256)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>There are many more</th>\n",
    "        <td>skipped</td>\n",
    "    </tr>\n",
    "    \n",
    "</table> \n",
    "\n",
    "- about 130M parameters\n",
    "\n",
    "## ResNets \n",
    "\n",
    "- typically tp go from $a^{[l]}$ to $a^{[l+2]}$ \n",
    "    - $z^{[l+1]} = w^{[l+1]}a^{[l]} + b^{[l+1]}$\n",
    "    - $a^{[l+1]} = g(z^{[l+1]})$\n",
    "    - $z^{[l+2]} = w^{[l+2]}a^{[l+1]} + b^{[l+2]}$\n",
    "    - $a^{[l+2]} = g(z^{[l+2]})$\n",
    "- take shortcuts such that $a^{[l+2]} = g(z^{[l+2]} + a^{[l]})$ which skips intermediate connections\n",
    "\n",
    "## 1x1 convolution\n",
    "\n",
    "- ex. 6x6x32 * 1x1x32 = 6x6xnumber_of_filters\n",
    "- ex. 28x28x192 * 1x1x32 = 23x23x32 (this shrinks $n_{c}$)\n",
    "\n",
    "## Inception network\n",
    "\n",
    "- with input 28x28x192, apply 3 different convolutions and 1 max-pooling\n",
    "    - 28x28x192 * 1x1 = 28x28x64\n",
    "    - 28x28x192 * 3x3 (same) = 28x28x128\n",
    "    - 28x28x192 * 5x5 (same) = 28x28x32\n",
    "    - 28x28x192 * POOL (same, s=1) = 28x28x32\n",
    "- total output is 28x28x256\n",
    "\n",
    "Computation reduction example\n",
    "- 28x28x192 * 5x5x192 (f=5,same,32) = 28x28x32. This requires 120M multiplications\n",
    "- 28x28x192 * 1x1x192 (16 filters) = 28x28x16 * 5x5x16 (32 filters) = 28x28x32. This requires 12.4M multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object localization\n",
    "\n",
    "- target label $y = \n",
    "\\begin{bmatrix}\n",
    "    p_{c} \\\\ \n",
    "    b_{x} \\\\ \n",
    "    b_{y} \\\\\n",
    "    b_{h} \\\\\n",
    "    b_{w} \\\\\n",
    "    c_{1} \\\\\n",
    "    c_{2} \\\\\n",
    "    c_{3} \\\\\n",
    "\\end{bmatrix}$\n",
    " \n",
    "- $p_{c}$: is there an object?\n",
    "- $b_{x}$: coordinate\n",
    "- $b_{y}$: coordinate\n",
    "- $b_{h}$: height\n",
    "- $b_{w}$: width\n",
    "- $c_{1}$: class #1\n",
    "- $c_{2}$: class #2\n",
    "- $c_{3}$: class #3\n",
    "- $L(\\hat{y}, y) = (\\hat{y}_{1} - y_{1})^{2} + (\\hat{y}_{2} - y_{2})^{2} + \\dots + (\\hat{y}_{8} - y_{8})^{2}$ if $y_{1} = 1$ \n",
    "- $L(\\hat{y}, y) = (\\hat{y}_{1} - y_{1})^{2}$ if $y_{1} = 0$\n",
    "\n",
    "## Sliding windows\n",
    "\n",
    "- create boxes and move it around inside the image. when image recognition algorithm detects the object, return. when finished, change the size of boxes and move them around again\n",
    "\n",
    "## Convolution implementation of sliding windows\n",
    "\n",
    "- 14x14x3 $\\xrightarrow{5x5}$ 10x10x16 $\\xrightarrow{2x2, POOL}$ 5x5x16 $\\xrightarrow{5x5, FC}$ 1x1x400 $\\xrightarrow{1x1, FC}$ 1x1x400 $\\xrightarrow{1x1, FC}$ 1x1x4\n",
    "- 16x16x3 $\\xrightarrow{5x5}$ 12x12x16 $\\xrightarrow{2x2, POOL}$ 6x6x16 $\\xrightarrow{5x5, FC}$ 2x2x400 $\\xrightarrow{1x1, FC}$ 2x2x400 $\\xrightarrow{1x1, FC}$ 2x2x4\n",
    "- 28x28x3 $\\xrightarrow{5x5}$ 24x24x16 $\\xrightarrow{2x2, POOL}$ 12x12x16 $\\xrightarrow{5x5, FC}$ 8x8x400 $\\xrightarrow{1x1, FC}$ 8x8x400 $\\xrightarrow{1x1, FC}$ 8x8x4\n",
    "\n",
    "## Bounding box predictions\n",
    "\n",
    "- split the image into multiple grid cells\n",
    "- assign object to grid cell by the midpoint of the object\n",
    "\n",
    "## Intersection over union\n",
    "\n",
    "- measure of the overlap between two bounding boxes\n",
    "- size of intersection / size of predicted bounding box\n",
    "- correct if IoU $\\ge 0.5$\n",
    "\n",
    "## Non-max suppression\n",
    "\n",
    "- cleans up multiple detections of same object\n",
    "- discard all boxes with $p_{c} \\le 0.6$\n",
    "- while there are any remaining boxes\n",
    "    - pick the box with the largest $p_{c}$, output that as a prediction\n",
    "    - discard any remaining box with IoU $\\ge 0.5$ with the box output in the previous step\n",
    "    \n",
    "## Anchor boxes\n",
    "\n",
    "- overlapping objects? create multiple (anchor) boxes\n",
    "- target label $y = \n",
    "\\begin{bmatrix}\n",
    "    p_{c} \\\\ \n",
    "    b_{x} \\\\ \n",
    "    b_{y} \\\\\n",
    "    b_{h} \\\\\n",
    "    b_{w} \\\\\n",
    "    c_{1} \\\\\n",
    "    c_{2} \\\\\n",
    "    c_{3} \\\\\n",
    "    p_{c} \\\\ \n",
    "    b_{x} \\\\ \n",
    "    b_{y} \\\\\n",
    "    b_{h} \\\\\n",
    "    b_{w} \\\\\n",
    "    c_{1} \\\\\n",
    "    c_{2} \\\\\n",
    "    c_{3} \\\\\n",
    "\\end{bmatrix}$\n",
    "- each object in training image is assigned to grid cell that contains object's midpoint and anchor box for the grid cell with highest IoU\n",
    "\n",
    "## YOLO algorithm\n",
    "\n",
    "- ex. training: 3x3x2 (number of anchors) x8 (5 + number of classes)\n",
    "- output: 3x3x16\n",
    "\n",
    "## Face verification\n",
    "\n",
    "- input image\n",
    "- output whether the input image is that of the claimed person\n",
    "\n",
    "## Face recognition\n",
    "\n",
    "- has database of $K$ persons\n",
    "- get an input image\n",
    "- output ID if the image is any of the $K$ persons (or not recognized)\n",
    "\n",
    "## One-shot learning\n",
    "\n",
    "- learning from one example to recognize the person again\n",
    "- \"similarity\" function d(img1, img2) = degree of difference between images\n",
    "\n",
    "## Siamese network\n",
    "\n",
    "- run different images on the same network and compare encodings $f(x^{(i)})$\n",
    "- if $x^{(i)}, x^{(j)}$ are the same person, $||f(x^{(i)}) - f(x^{(j)})||^{2}$ is small\n",
    "- if $x^{(i)}, x^{(j)}$ are the different person, $||f(x^{(i)}) - f(x^{(j)})||^{2}$ is large\n",
    "\n",
    "## Triplet loss\n",
    "\n",
    "- anchor, positive, negative\n",
    "- want $||f(A)-f(P)||^{2} \\le ||f(A)-f(N)||^{2} - \\alpha$ (margin to avoid parameters being all zeros)\n",
    "- $L(A,P,N) = max(||f(A)-f(P)||^{2} - ||f(A)-f(N)||^{2} + \\alpha, 0)$\n",
    "- $J = \\displaystyle\\sum_{i=1}^{m}L(A^{(i)}, P^{(i)}, N^{(i)})$\n",
    "- during training, if A,P,N are chosen randomly, $d(A,P) + \\alpha \\le d(A,N)$ is easily satisfied\n",
    "    - choose triplets that are \"hard\" to train on $d(A,P) \\approx d(A,N)$\n",
    "    \n",
    "## Learning the similarity function\n",
    "\n",
    "- $\\hat{y} = \\sigma\\left(\\displaystyle\\sum_{k=1}^{128}w_{i}|f(x^{(i)})_{k} - f(x^{(j)})_{k}| + b\\right)$\n",
    "\n",
    "## Neural style transfer\n",
    "\n",
    "- content image (C), style image (S), generated image (G)\n",
    "- cost function $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$\n",
    "- initialize $G$ randomly\n",
    "- use gradient descent to minimize $J(G)$\n",
    "    - $G = G - \\dfrac{\\partial}{\\partial G}J(G)$\n",
    "    \n",
    "## Content cost function\n",
    "\n",
    "- say you use hidden layer $l$ to compute content cost\n",
    "- use pre-trained ConvNet (eg. VGG network)\n",
    "- let $a^{[l](C)}$ and $a^{[l](G)}$ be the activation of layer $l$ on the images\n",
    "- if $a^{[l](C)}$ and $a^{[l](G)}$ are similar, both images have similar content\n",
    "    - $J_{content}(C,G) = \\dfrac{1}{2}||a^{[l](C)} - a^{[l](G)}||^{2}$\n",
    "    \n",
    "## Style cost function\n",
    "\n",
    "- style matrix\n",
    "    - let $a_{i,j,k}^{l}$ = activation at $(i,j,k)$ (height, weight, channel)\n",
    "    - $G^{[l]}$ is $n_{c}^{[l]}$ x $n_{c}^{[l]}$\n",
    "    - $G_{kk'}^{[l]} = \\displaystyle\\sum_{i=1}^{n_{H}^{[l]}}\\displaystyle\\sum_{j=1}^{n_{W}^{[l]}}a_{ijk}^[l]a_{ijk'}^[l]$ (do this for both style and generated) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
